{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==1.5.2 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (1.5.2)\n",
      "Requirement already satisfied: pandas==2.2.3 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (2.2.3)\n",
      "Requirement already satisfied: mlflow==2.18.0 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (2.18.0)\n",
      "Requirement already satisfied: xgboost==2.1.1 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (2.1.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from scikit-learn==1.5.2->-r requirements.txt (line 1)) (2.3.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from scikit-learn==1.5.2->-r requirements.txt (line 1)) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from scikit-learn==1.5.2->-r requirements.txt (line 1)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from scikit-learn==1.5.2->-r requirements.txt (line 1)) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from pandas==2.2.3->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from pandas==2.2.3->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from pandas==2.2.3->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: mlflow-skinny==2.18.0 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from mlflow==2.18.0->-r requirements.txt (line 3)) (2.18.0)\n",
      "Requirement already satisfied: Flask<4 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from mlflow==2.18.0->-r requirements.txt (line 3)) (3.1.2)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from mlflow==2.18.0->-r requirements.txt (line 3)) (1.17.2)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from mlflow==2.18.0->-r requirements.txt (line 3)) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from mlflow==2.18.0->-r requirements.txt (line 3)) (3.4.3)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from mlflow==2.18.0->-r requirements.txt (line 3)) (3.10)\n",
      "Requirement already satisfied: matplotlib<4 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from mlflow==2.18.0->-r requirements.txt (line 3)) (3.10.7)\n",
      "Requirement already satisfied: pyarrow<19,>=4.0.0 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from mlflow==2.18.0->-r requirements.txt (line 3)) (18.1.0)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from mlflow==2.18.0->-r requirements.txt (line 3)) (2.0.44)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from mlflow==2.18.0->-r requirements.txt (line 3)) (3.1.6)\n",
      "Requirement already satisfied: gunicorn<24 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from mlflow==2.18.0->-r requirements.txt (line 3)) (23.0.0)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 3)) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 3)) (8.3.1)\n",
      "Requirement already satisfied: cloudpickle<4 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 3)) (3.1.2)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 3)) (0.73.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 3)) (3.1.45)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 3)) (8.7.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 3)) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 3)) (1.38.0)\n",
      "Requirement already satisfied: packaging<25 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 3)) (24.2)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 3)) (5.29.5)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 3)) (6.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 3)) (2.32.5)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 3)) (0.5.3)\n",
      "Requirement already satisfied: Mako in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow==2.18.0->-r requirements.txt (line 3)) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow==2.18.0->-r requirements.txt (line 3)) (4.15.0)\n",
      "Requirement already satisfied: google-auth~=2.0 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 3)) (2.43.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from docker<8,>=4.0.0->mlflow==2.18.0->-r requirements.txt (line 3)) (2.5.0)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from Flask<4->mlflow==2.18.0->-r requirements.txt (line 3)) (1.9.0)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from Flask<4->mlflow==2.18.0->-r requirements.txt (line 3)) (2.2.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from Flask<4->mlflow==2.18.0->-r requirements.txt (line 3)) (3.0.3)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from Flask<4->mlflow==2.18.0->-r requirements.txt (line 3)) (3.1.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 3)) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 3)) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 3)) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 3)) (4.9.1)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from graphene<4->mlflow==2.18.0->-r requirements.txt (line 3)) (3.2.7)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from graphene<4->mlflow==2.18.0->-r requirements.txt (line 3)) (3.2.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 3)) (3.23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from matplotlib<4->mlflow==2.18.0->-r requirements.txt (line 3)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from matplotlib<4->mlflow==2.18.0->-r requirements.txt (line 3)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from matplotlib<4->mlflow==2.18.0->-r requirements.txt (line 3)) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from matplotlib<4->mlflow==2.18.0->-r requirements.txt (line 3)) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from matplotlib<4->mlflow==2.18.0->-r requirements.txt (line 3)) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from matplotlib<4->mlflow==2.18.0->-r requirements.txt (line 3)) (3.2.5)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 3)) (0.59b0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas==2.2.3->-r requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 3)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 3)) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 3)) (2025.11.12)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow==2.18.0->-r requirements.txt (line 3)) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project notebook\n",
    "\n",
    "The following notebook is an excerpt and re-written example from a _real_ production model.\n",
    "\n",
    "The overall purpose of the ML algorithm is to identify users on the website that are new possible customers. This is done by collecting behaviour data from the users as input, and the target is whether they converted/turned into customers -- essentially a classification problem. \n",
    "\n",
    "This notebook only focuses on the data processing part. As you know, there are multiple steps in an ML pipeline, and it's not always they are neatly separated like this. For the exam project, they will not be, and that is part of the challenge for you. For production code, it should also not be Python notebooks since, as you may well see, it is difficult to work with and collaborate on them in an automated way.\n",
    "\n",
    "There is a lot of \"fluff\" in such a notebook. This ranges from comments and markdown cells to commented out code and random print statements. That is not necessary in a properly managed project where you can use git to check the version history and such. \n",
    "\n",
    "What is important for you is the identify the entry points into the code and segment them out into easily understandable chunks. Additionally, you might want to follow some basic code standards, such as:\n",
    "\n",
    "- Import only libraries in the beginning of the files\n",
    "- Define functions in the top of the scripts, or if used multiple places, move into a util.py script or such\n",
    "- Remove unused/commented out code\n",
    "- Follow the [PEP 8](https://peps.python.org/pep-0008/) style guide (and others)\n",
    "  \n",
    "Another thing to note is that comments can be misleading. Even if the markdown cell or inline comments says it does _X_, don't be surprised if it actually does _Y_. Sometimes additional text can be a blessing, but it can also be a curse sometimes. Remember, though, that your task is to make sure the code runs as before after refactoring the notebook into other files, not update/improve the model or flow to reflect what the comments might say.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PROCESSING\n",
    "\n",
    "In this section, we will perform Exploratory Data Analysis (EDA) to better understand the dataset before proceeding with more advanced analysis. EDA helps us get a sense of the data’s structure, identify patterns, and spot any potential issues like missing values or outliers. By doing so, we can gain a clearer understanding of the data's key characteristics.\n",
    "\n",
    "We will start with summary statistics to review basic measures like mean, median, and variance, providing an initial overview of the data distribution. Then, we’ll create visualizations such as histograms, box plots, and scatter plots to explore relationships between variables, check for any skewness, and highlight outliers.\n",
    "\n",
    "The purpose of this EDA is to ensure that the dataset is clean and well-structured for further analysis. This step also helps us identify any necessary data transformations and informs decisions on which features might be most relevant for modeling in later stages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create artifact directory\n",
    "We want to create a directory for storing all the artifacts in the current directory. Users can load all the artifacts later for data cleaning pipelines and inferencing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbutils.widgets.text(\"Training data max date\", \"2024-01-31\")\n",
    "# dbutils.widgets.text(\"Training data min date\", \"2024-01-01\")\n",
    "# max_date = dbutils.widgets.get(\"Training data max date\")\n",
    "# min_date = dbutils.widgets.get(\"Training data min date\")\n",
    "\n",
    "# testnng\n",
    "max_date = \"2024-01-31\"\n",
    "min_date = \"2024-01-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#import shutil\n",
    "#from pprint import pprint\n",
    "\n",
    "# shutil.rmtree(\"./artifacts\",ignore_errors=True)\n",
    "#os.makedirs(\"artifacts\",exist_ok=True)\n",
    "#print(\"Created artifacts directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas dataframe print options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import warnings\n",
    "\n",
    "#warnings.filterwarnings('ignore')\n",
    "#pd.set_option('display.float_format',lambda x: \"%.3f\" % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions\n",
    "\n",
    "* **describe_numeric_col**: Calculates various descriptive stats for a numeric column in a dataframe.\n",
    "* **impute_missing_values**: Imputes the mean/median for numeric columns or the mode for other types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_numeric_col(x):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        x (pd.Series): Pandas col to describe.\n",
    "    Output:\n",
    "        y (pd.Series): Pandas series with descriptive stats. \n",
    "    \"\"\"\n",
    "    return pd.Series(\n",
    "        [x.count(), x.isnull().count(), x.mean(), x.min(), x.max()],\n",
    "        index=[\"Count\", \"Missing\", \"Mean\", \"Min\", \"Max\"]\n",
    "    )\n",
    "\n",
    "def impute_missing_values(x, method=\"mean\"):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        x (pd.Series): Pandas col to describe.\n",
    "        method (str): Values: \"mean\", \"median\"\n",
    "    \"\"\"\n",
    "    if (x.dtype == \"float64\") | (x.dtype == \"int64\"):\n",
    "        x = x.fillna(x.mean()) if method==\"mean\" else x.fillna(x.median())\n",
    "    else:\n",
    "        x = x.fillna(x.mode()[0])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data\n",
    "\n",
    "We read the latest data from our data lake source. Here we load it locally after having pulled it from DVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dvc pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data\n",
      "Total rows: lead_id                              12345\n",
      "lead_indicator                       11753\n",
      "date_part                            12345\n",
      "is_active                            12345\n",
      "marketing_consent                    12345\n",
      "first_booking                        12345\n",
      "existing_customer                    12345\n",
      "last_seen                            12345\n",
      "source                               12345\n",
      "domain                               12345\n",
      "country                              12345\n",
      "visited_learn_more_before_booking    12345\n",
      "visited_faq                          12345\n",
      "purchases                            12345\n",
      "time_spent                           12345\n",
      "customer_group                       12345\n",
      "onboarding                           12345\n",
      "customer_code                        12294\n",
      "n_visits                             12345\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_id</th>\n",
       "      <th>lead_indicator</th>\n",
       "      <th>date_part</th>\n",
       "      <th>is_active</th>\n",
       "      <th>marketing_consent</th>\n",
       "      <th>first_booking</th>\n",
       "      <th>existing_customer</th>\n",
       "      <th>last_seen</th>\n",
       "      <th>source</th>\n",
       "      <th>domain</th>\n",
       "      <th>country</th>\n",
       "      <th>visited_learn_more_before_booking</th>\n",
       "      <th>visited_faq</th>\n",
       "      <th>purchases</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>customer_group</th>\n",
       "      <th>onboarding</th>\n",
       "      <th>customer_code</th>\n",
       "      <th>n_visits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-24</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-01-25</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-01-13</td>\n",
       "      <td>organic</td>\n",
       "      <td>.dk</td>\n",
       "      <td>US</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>115.064399</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-01-24</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-01-6</td>\n",
       "      <td>signup</td>\n",
       "      <td>.dk</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>119.907446</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>AGMVEYWACO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-01-27</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-01-30</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-01-30</td>\n",
       "      <td>signup</td>\n",
       "      <td>.dk</td>\n",
       "      <td>DK</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>100.473670</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>STWPXVNOWA</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-01-28</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-01-10</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-01-11</td>\n",
       "      <td>li</td>\n",
       "      <td>.cn</td>\n",
       "      <td>US</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>98.571691</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>HZOKZERLZD</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-5</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-01-30</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-01-25</td>\n",
       "      <td>fb</td>\n",
       "      <td>.com</td>\n",
       "      <td>US</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>101.996242</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>CVLIHCAPZN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lead_id  lead_indicator   date_part  is_active  marketing_consent  \\\n",
       "0        0             0.0  2024-01-24          0               True   \n",
       "1        1             NaN   2024-01-1          1               True   \n",
       "2        2             1.0  2024-01-27          0               True   \n",
       "3        3             1.0  2024-01-28          0              False   \n",
       "4        4             0.0   2024-01-5          0               True   \n",
       "\n",
       "  first_booking  existing_customer   last_seen   source domain country  \\\n",
       "0    2024-01-25              False  2024-01-13  organic    .dk      US   \n",
       "1    2024-01-24              False   2024-01-6   signup    .dk      US   \n",
       "2    2024-01-30               True  2024-01-30   signup    .dk      DK   \n",
       "3    2024-01-10              False  2024-01-11       li    .cn      US   \n",
       "4    2024-01-30               True  2024-01-25       fb   .com      US   \n",
       "\n",
       "   visited_learn_more_before_booking  visited_faq  purchases  time_spent  \\\n",
       "0                                  8           10          5  115.064399   \n",
       "1                                  0            3          5  119.907446   \n",
       "2                                  7           10          3  100.473670   \n",
       "3                                 10           10          4   98.571691   \n",
       "4                                  5            1          5  101.996242   \n",
       "\n",
       "   customer_group  onboarding customer_code  n_visits  \n",
       "0               2        True           NaN         9  \n",
       "1               2       False    AGMVEYWACO         1  \n",
       "2               5       False    STWPXVNOWA        16  \n",
       "3               4        True    HZOKZERLZD        16  \n",
       "4               9       False    CVLIHCAPZN         2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Loading training data\")\n",
    "\n",
    "data = pd.read_csv(\"./artifacts/raw_data.csv\")\n",
    "\n",
    "print(\"Total rows:\", data.count())\n",
    "display(data.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "if not max_date:\n",
    "    max_date = pd.to_datetime(datetime.datetime.now().date()).date()\n",
    "else:\n",
    "    max_date = pd.to_datetime(max_date).date()\n",
    "\n",
    "min_date = pd.to_datetime(min_date).date()\n",
    "\n",
    "# Time limit data\n",
    "data[\"date_part\"] = pd.to_datetime(data[\"date_part\"]).dt.date\n",
    "data = data[(data[\"date_part\"] >= min_date) & (data[\"date_part\"] <= max_date)]\n",
    "\n",
    "min_date = data[\"date_part\"].min()\n",
    "max_date = data[\"date_part\"].max()\n",
    "date_limits = {\"min_date\": str(min_date), \"max_date\": str(max_date)}\n",
    "with open(\"./artifacts/date_limits.json\", \"w\") as f:\n",
    "    json.dump(date_limits, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "\n",
    "Not all columns are relevant for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(\n",
    "    [\n",
    "        \"is_active\", \"marketing_consent\", \"first_booking\", \"existing_customer\", \"last_seen\"\n",
    "    ],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing columns that will be added back after the EDA\n",
    "data = data.drop(\n",
    "    [\"domain\", \"country\", \"visited_learn_more_before_booking\", \"visited_faq\"],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "* Remove rows with empty target variable\n",
    "* Remove rows with other invalid column data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target value counter\n",
      "0.0 :  0.5318352059925093\n",
      "1.0 :  0.4681647940074906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/8sx16ndx5ds22xjw_x_3lzyh0000gn/T/ipykernel_22314/1067272918.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[\"lead_indicator\"].replace(\"\", np.nan, inplace=True)\n",
      "/var/folders/ns/8sx16ndx5ds22xjw_x_3lzyh0000gn/T/ipykernel_22314/1067272918.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[\"lead_id\"].replace(\"\", np.nan, inplace=True)\n",
      "/var/folders/ns/8sx16ndx5ds22xjw_x_3lzyh0000gn/T/ipykernel_22314/1067272918.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[\"customer_code\"].replace(\"\", np.nan, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_id</th>\n",
       "      <th>lead_indicator</th>\n",
       "      <th>date_part</th>\n",
       "      <th>source</th>\n",
       "      <th>purchases</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>customer_group</th>\n",
       "      <th>onboarding</th>\n",
       "      <th>customer_code</th>\n",
       "      <th>n_visits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-01-27</td>\n",
       "      <td>signup</td>\n",
       "      <td>3</td>\n",
       "      <td>100.473670</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>STWPXVNOWA</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-11</td>\n",
       "      <td>signup</td>\n",
       "      <td>8</td>\n",
       "      <td>105.898925</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>JWLXPVANUM</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>signup</td>\n",
       "      <td>6</td>\n",
       "      <td>86.717225</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>WNKCTHUHYI</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-01-07</td>\n",
       "      <td>signup</td>\n",
       "      <td>5</td>\n",
       "      <td>106.951999</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>INIQMTGGOO</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-20</td>\n",
       "      <td>signup</td>\n",
       "      <td>3</td>\n",
       "      <td>94.667990</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>SJGDAANOYJ</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12328</th>\n",
       "      <td>12328</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>signup</td>\n",
       "      <td>2</td>\n",
       "      <td>98.999168</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>AYAVVZAMGV</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12330</th>\n",
       "      <td>12330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>signup</td>\n",
       "      <td>6</td>\n",
       "      <td>101.389931</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>YFKCVZSAJF</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12334</th>\n",
       "      <td>12334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-21</td>\n",
       "      <td>signup</td>\n",
       "      <td>1</td>\n",
       "      <td>93.840461</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>ROVGLTVJNL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12337</th>\n",
       "      <td>12337</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>signup</td>\n",
       "      <td>0</td>\n",
       "      <td>110.320204</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>BGQNNVRTDH</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12343</th>\n",
       "      <td>12343</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-01-29</td>\n",
       "      <td>signup</td>\n",
       "      <td>8</td>\n",
       "      <td>105.712866</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>UNUSNTTYXR</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2937 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lead_id  lead_indicator   date_part  source  purchases  time_spent  \\\n",
       "2            2             1.0  2024-01-27  signup          3  100.473670   \n",
       "10          10             0.0  2024-01-11  signup          8  105.898925   \n",
       "13          13             0.0  2024-01-22  signup          6   86.717225   \n",
       "17          17             1.0  2024-01-07  signup          5  106.951999   \n",
       "19          19             0.0  2024-01-20  signup          3   94.667990   \n",
       "...        ...             ...         ...     ...        ...         ...   \n",
       "12328    12328             1.0  2024-01-01  signup          2   98.999168   \n",
       "12330    12330             1.0  2024-01-14  signup          6  101.389931   \n",
       "12334    12334             0.0  2024-01-21  signup          1   93.840461   \n",
       "12337    12337             1.0  2024-01-03  signup          0  110.320204   \n",
       "12343    12343             1.0  2024-01-29  signup          8  105.712866   \n",
       "\n",
       "       customer_group  onboarding customer_code  n_visits  \n",
       "2                   5       False    STWPXVNOWA        16  \n",
       "10                  4        True    JWLXPVANUM         4  \n",
       "13                  6        True    WNKCTHUHYI         5  \n",
       "17                  8       False    INIQMTGGOO         8  \n",
       "19                  9        True    SJGDAANOYJ        20  \n",
       "...               ...         ...           ...       ...  \n",
       "12328               5        True    AYAVVZAMGV        14  \n",
       "12330               4        True    YFKCVZSAJF        18  \n",
       "12334               5        True    ROVGLTVJNL         1  \n",
       "12337               6        True    BGQNNVRTDH        18  \n",
       "12343               8        True    UNUSNTTYXR        18  \n",
       "\n",
       "[2937 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data[\"lead_indicator\"].replace(\"\", np.nan, inplace=True)\n",
    "data[\"lead_id\"].replace(\"\", np.nan, inplace=True)\n",
    "data[\"customer_code\"].replace(\"\", np.nan, inplace=True)\n",
    "\n",
    "data = data.dropna(axis=0, subset=[\"lead_indicator\"])\n",
    "data = data.dropna(axis=0, subset=[\"lead_id\"])\n",
    "\n",
    "data = data[data.source == \"signup\"]\n",
    "result=data.lead_indicator.value_counts(normalize = True)\n",
    "\n",
    "print(\"Target value counter\")\n",
    "for val, n in zip(result.index, result):\n",
    "    print(val, \": \", n)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create categorical data columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed lead_id to object type\n",
      "Changed lead_indicator to object type\n",
      "Changed customer_group to object type\n",
      "Changed onboarding to object type\n",
      "Changed source to object type\n",
      "Changed customer_code to object type\n"
     ]
    }
   ],
   "source": [
    "vars = [\n",
    "    \"lead_id\", \"lead_indicator\", \"customer_group\", \"onboarding\", \"source\", \"customer_code\"\n",
    "]\n",
    "\n",
    "for col in vars:\n",
    "    data[col] = data[col].astype(\"object\")\n",
    "    print(f\"Changed {col} to object type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate categorical and continuous columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Continuous columns: \n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pprint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m cat_vars = data.loc[:, (data.dtypes==\u001b[33m\"\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mContinuous columns: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mpprint\u001b[49m(\u001b[38;5;28mlist\u001b[39m(cont_vars.columns), indent=\u001b[32m4\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Categorical columns: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m pprint(\u001b[38;5;28mlist\u001b[39m(cat_vars.columns), indent=\u001b[32m4\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'pprint' is not defined"
     ]
    }
   ],
   "source": [
    "cont_vars = data.loc[:, ((data.dtypes==\"float64\")|(data.dtypes==\"int64\"))]\n",
    "cat_vars = data.loc[:, (data.dtypes==\"object\")]\n",
    "\n",
    "print(\"\\nContinuous columns: \\n\")\n",
    "pprint(list(cont_vars.columns), indent=4)\n",
    "print(\"\\n Categorical columns: \\n\")\n",
    "pprint(list(cat_vars.columns), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers\n",
    "\n",
    "Outliers are data points that significantly differ from the majority of observations in a dataset and can distort statistical analysis or model performance. To identify and remove outliers, one common method is to use the Z-score, which measures how many standard deviations a data point is from the mean. Data points with a Z-score greater than 2 (or sometimes 3) standard deviations away from the mean are typically considered outliers. By applying this threshold, we can filter out values that fall outside the normal range of the data, ensuring that the remaining dataset is more representative and less influenced by extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>purchases</th>\n",
       "      <td>2937.0</td>\n",
       "      <td>2937.0</td>\n",
       "      <td>5.000105</td>\n",
       "      <td>0.578163</td>\n",
       "      <td>9.494701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_spent</th>\n",
       "      <td>2937.0</td>\n",
       "      <td>2937.0</td>\n",
       "      <td>100.015230</td>\n",
       "      <td>80.082404</td>\n",
       "      <td>119.902405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_visits</th>\n",
       "      <td>2937.0</td>\n",
       "      <td>2937.0</td>\n",
       "      <td>8.884043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.334292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Count  Missing        Mean        Min         Max\n",
       "purchases   2937.0   2937.0    5.000105   0.578163    9.494701\n",
       "time_spent  2937.0   2937.0  100.015230  80.082404  119.902405\n",
       "n_visits    2937.0   2937.0    8.884043   1.000000   22.334292"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_vars = cont_vars.apply(lambda x: x.clip(lower = (x.mean()-2*x.std()),\n",
    "                                             upper = (x.mean()+2*x.std())))\n",
    "outlier_summary = cont_vars.apply(describe_numeric_col).T\n",
    "outlier_summary.to_csv('./artifacts/outlier_summary.csv')\n",
    "outlier_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute data\n",
    "\n",
    "In real-world datasets, missing data is a common occurrence due to various factors such as human error, incomplete data collection processes, or system failures. These gaps in the data can hinder analysis and lead to biased results if not properly addressed. Since many analytical and machine learning algorithms require complete data, handling missing values is an essential step in the data preprocessing phase.\n",
    "\n",
    "In the next code block, we will handle missing data by performing imputation. For numerical columns, we will replace missing values with the mean or median of the entire column, which provides a reasonable estimate based on the existing data. For categorical columns (object type), we will use the mode, or most frequent value, to fill in missing entries. This approach helps us maintain a complete dataset while ensuring that the imputed values align with the general distribution of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_id</th>\n",
       "      <th>lead_indicator</th>\n",
       "      <th>date_part</th>\n",
       "      <th>source</th>\n",
       "      <th>customer_group</th>\n",
       "      <th>onboarding</th>\n",
       "      <th>customer_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-06</td>\n",
       "      <td>signup</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>AAAEJOLSFX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AACEDUWABX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAJURHRBIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAMFOUYNWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAXKODEIPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>12328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2933</th>\n",
       "      <td>12330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2934</th>\n",
       "      <td>12334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>12337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>12343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2937 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     lead_id lead_indicator   date_part  source customer_group onboarding  \\\n",
       "0          2            0.0  2024-01-06  signup              5       True   \n",
       "1         10            NaN         NaN     NaN            NaN        NaN   \n",
       "2         13            NaN         NaN     NaN            NaN        NaN   \n",
       "3         17            NaN         NaN     NaN            NaN        NaN   \n",
       "4         19            NaN         NaN     NaN            NaN        NaN   \n",
       "...      ...            ...         ...     ...            ...        ...   \n",
       "2932   12328            NaN         NaN     NaN            NaN        NaN   \n",
       "2933   12330            NaN         NaN     NaN            NaN        NaN   \n",
       "2934   12334            NaN         NaN     NaN            NaN        NaN   \n",
       "2935   12337            NaN         NaN     NaN            NaN        NaN   \n",
       "2936   12343            NaN         NaN     NaN            NaN        NaN   \n",
       "\n",
       "     customer_code  \n",
       "0       AAAEJOLSFX  \n",
       "1       AACEDUWABX  \n",
       "2       AAJURHRBIM  \n",
       "3       AAMFOUYNWS  \n",
       "4       AAXKODEIPG  \n",
       "...            ...  \n",
       "2932           NaN  \n",
       "2933           NaN  \n",
       "2934           NaN  \n",
       "2935           NaN  \n",
       "2936           NaN  \n",
       "\n",
       "[2937 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_missing_impute = cat_vars.mode(numeric_only=False, dropna=True)\n",
    "cat_missing_impute.to_csv(\"./artifacts/cat_missing_impute.csv\")\n",
    "cat_missing_impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>purchases</th>\n",
       "      <td>2937.0</td>\n",
       "      <td>2937.0</td>\n",
       "      <td>5.000105</td>\n",
       "      <td>0.578163</td>\n",
       "      <td>9.494701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_spent</th>\n",
       "      <td>2937.0</td>\n",
       "      <td>2937.0</td>\n",
       "      <td>100.015230</td>\n",
       "      <td>80.082404</td>\n",
       "      <td>119.902405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_visits</th>\n",
       "      <td>2937.0</td>\n",
       "      <td>2937.0</td>\n",
       "      <td>8.884043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.334292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Count  Missing        Mean        Min         Max\n",
       "purchases   2937.0   2937.0    5.000105   0.578163    9.494701\n",
       "time_spent  2937.0   2937.0  100.015230  80.082404  119.902405\n",
       "n_visits    2937.0   2937.0    8.884043   1.000000   22.334292"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Continuous variables missing values\n",
    "cont_vars = cont_vars.apply(impute_missing_values)\n",
    "cont_vars.apply(describe_numeric_col).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/8sx16ndx5ds22xjw_x_3lzyh0000gn/T/ipykernel_22314/3933436795.py:22: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  x = x.fillna(x.mode()[0])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_id</th>\n",
       "      <th>lead_indicator</th>\n",
       "      <th>date_part</th>\n",
       "      <th>source</th>\n",
       "      <th>customer_group</th>\n",
       "      <th>onboarding</th>\n",
       "      <th>customer_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-01-27</td>\n",
       "      <td>signup</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>STWPXVNOWA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-11</td>\n",
       "      <td>signup</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>JWLXPVANUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>signup</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>WNKCTHUHYI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-01-07</td>\n",
       "      <td>signup</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>INIQMTGGOO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-20</td>\n",
       "      <td>signup</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>SJGDAANOYJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12328</th>\n",
       "      <td>12328</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>signup</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>AYAVVZAMGV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12330</th>\n",
       "      <td>12330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>signup</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>YFKCVZSAJF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12334</th>\n",
       "      <td>12334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-21</td>\n",
       "      <td>signup</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>ROVGLTVJNL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12337</th>\n",
       "      <td>12337</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>signup</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>BGQNNVRTDH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12343</th>\n",
       "      <td>12343</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-01-29</td>\n",
       "      <td>signup</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>UNUSNTTYXR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2937 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lead_id  lead_indicator   date_part  source  customer_group  \\\n",
       "2            2             1.0  2024-01-27  signup               5   \n",
       "10          10             0.0  2024-01-11  signup               4   \n",
       "13          13             0.0  2024-01-22  signup               6   \n",
       "17          17             1.0  2024-01-07  signup               8   \n",
       "19          19             0.0  2024-01-20  signup               9   \n",
       "...        ...             ...         ...     ...             ...   \n",
       "12328    12328             1.0  2024-01-01  signup               5   \n",
       "12330    12330             1.0  2024-01-14  signup               4   \n",
       "12334    12334             0.0  2024-01-21  signup               5   \n",
       "12337    12337             1.0  2024-01-03  signup               6   \n",
       "12343    12343             1.0  2024-01-29  signup               8   \n",
       "\n",
       "       onboarding customer_code  \n",
       "2           False    STWPXVNOWA  \n",
       "10           True    JWLXPVANUM  \n",
       "13           True    WNKCTHUHYI  \n",
       "17          False    INIQMTGGOO  \n",
       "19           True    SJGDAANOYJ  \n",
       "...           ...           ...  \n",
       "12328        True    AYAVVZAMGV  \n",
       "12330        True    YFKCVZSAJF  \n",
       "12334        True    ROVGLTVJNL  \n",
       "12337        True    BGQNNVRTDH  \n",
       "12343        True    UNUSNTTYXR  \n",
       "\n",
       "[2937 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_vars.loc[cat_vars['customer_code'].isna(),'customer_code'] = 'None'\n",
    "cat_vars = cat_vars.apply(impute_missing_values)\n",
    "cat_vars.apply(lambda x: pd.Series([x.count(), x.isnull().sum()], index = ['Count', 'Missing'])).T\n",
    "cat_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data standardisation\n",
    "\n",
    "Standardization, or scaling, becomes necessary when continuous independent variables are measured on different scales, as this can lead to unequal contributions to the analysis. The objective is to rescale these variables so they have comparable ranges and/or variances, ensuring a more balanced influence in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved scaler in artifacts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchases</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>n_visits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.271612</td>\n",
       "      <td>0.512086</td>\n",
       "      <td>0.703093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.832368</td>\n",
       "      <td>0.648330</td>\n",
       "      <td>0.140619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.608065</td>\n",
       "      <td>0.166620</td>\n",
       "      <td>0.187492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.495914</td>\n",
       "      <td>0.674776</td>\n",
       "      <td>0.328110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.271612</td>\n",
       "      <td>0.366288</td>\n",
       "      <td>0.890585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>0.159461</td>\n",
       "      <td>0.475057</td>\n",
       "      <td>0.609348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2933</th>\n",
       "      <td>0.608065</td>\n",
       "      <td>0.535096</td>\n",
       "      <td>0.796839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2934</th>\n",
       "      <td>0.047310</td>\n",
       "      <td>0.345506</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.759362</td>\n",
       "      <td>0.796839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>0.832368</td>\n",
       "      <td>0.643658</td>\n",
       "      <td>0.796839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2937 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      purchases  time_spent  n_visits\n",
       "0      0.271612    0.512086  0.703093\n",
       "1      0.832368    0.648330  0.140619\n",
       "2      0.608065    0.166620  0.187492\n",
       "3      0.495914    0.674776  0.328110\n",
       "4      0.271612    0.366288  0.890585\n",
       "...         ...         ...       ...\n",
       "2932   0.159461    0.475057  0.609348\n",
       "2933   0.608065    0.535096  0.796839\n",
       "2934   0.047310    0.345506  0.000000\n",
       "2935   0.000000    0.759362  0.796839\n",
       "2936   0.832368    0.643658  0.796839\n",
       "\n",
       "[2937 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "scaler_path = \"./artifacts/scaler.pkl\"\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(cont_vars)\n",
    "\n",
    "joblib.dump(value=scaler, filename=scaler_path)\n",
    "print(\"Saved scaler in artifacts\")\n",
    "\n",
    "cont_vars = pd.DataFrame(scaler.transform(cont_vars), columns=cont_vars.columns)\n",
    "cont_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleansed and combined.\n",
      "Rows: 2937\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_id</th>\n",
       "      <th>lead_indicator</th>\n",
       "      <th>date_part</th>\n",
       "      <th>source</th>\n",
       "      <th>customer_group</th>\n",
       "      <th>onboarding</th>\n",
       "      <th>customer_code</th>\n",
       "      <th>purchases</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>n_visits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-01-27</td>\n",
       "      <td>signup</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>STWPXVNOWA</td>\n",
       "      <td>0.271612</td>\n",
       "      <td>0.512086</td>\n",
       "      <td>0.703093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-11</td>\n",
       "      <td>signup</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>JWLXPVANUM</td>\n",
       "      <td>0.832368</td>\n",
       "      <td>0.648330</td>\n",
       "      <td>0.140619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>signup</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>WNKCTHUHYI</td>\n",
       "      <td>0.608065</td>\n",
       "      <td>0.166620</td>\n",
       "      <td>0.187492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-01-07</td>\n",
       "      <td>signup</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>INIQMTGGOO</td>\n",
       "      <td>0.495914</td>\n",
       "      <td>0.674776</td>\n",
       "      <td>0.328110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-20</td>\n",
       "      <td>signup</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>SJGDAANOYJ</td>\n",
       "      <td>0.271612</td>\n",
       "      <td>0.366288</td>\n",
       "      <td>0.890585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>12328</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>signup</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>AYAVVZAMGV</td>\n",
       "      <td>0.159461</td>\n",
       "      <td>0.475057</td>\n",
       "      <td>0.609348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2933</th>\n",
       "      <td>12330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>signup</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>YFKCVZSAJF</td>\n",
       "      <td>0.608065</td>\n",
       "      <td>0.535096</td>\n",
       "      <td>0.796839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2934</th>\n",
       "      <td>12334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-21</td>\n",
       "      <td>signup</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>ROVGLTVJNL</td>\n",
       "      <td>0.047310</td>\n",
       "      <td>0.345506</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>12337</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>signup</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>BGQNNVRTDH</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.759362</td>\n",
       "      <td>0.796839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>12343</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-01-29</td>\n",
       "      <td>signup</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>UNUSNTTYXR</td>\n",
       "      <td>0.832368</td>\n",
       "      <td>0.643658</td>\n",
       "      <td>0.796839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2937 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lead_id  lead_indicator   date_part  source  customer_group  onboarding  \\\n",
       "0           2             1.0  2024-01-27  signup               5       False   \n",
       "1          10             0.0  2024-01-11  signup               4        True   \n",
       "2          13             0.0  2024-01-22  signup               6        True   \n",
       "3          17             1.0  2024-01-07  signup               8       False   \n",
       "4          19             0.0  2024-01-20  signup               9        True   \n",
       "...       ...             ...         ...     ...             ...         ...   \n",
       "2932    12328             1.0  2024-01-01  signup               5        True   \n",
       "2933    12330             1.0  2024-01-14  signup               4        True   \n",
       "2934    12334             0.0  2024-01-21  signup               5        True   \n",
       "2935    12337             1.0  2024-01-03  signup               6        True   \n",
       "2936    12343             1.0  2024-01-29  signup               8        True   \n",
       "\n",
       "     customer_code  purchases  time_spent  n_visits  \n",
       "0       STWPXVNOWA   0.271612    0.512086  0.703093  \n",
       "1       JWLXPVANUM   0.832368    0.648330  0.140619  \n",
       "2       WNKCTHUHYI   0.608065    0.166620  0.187492  \n",
       "3       INIQMTGGOO   0.495914    0.674776  0.328110  \n",
       "4       SJGDAANOYJ   0.271612    0.366288  0.890585  \n",
       "...            ...        ...         ...       ...  \n",
       "2932    AYAVVZAMGV   0.159461    0.475057  0.609348  \n",
       "2933    YFKCVZSAJF   0.608065    0.535096  0.796839  \n",
       "2934    ROVGLTVJNL   0.047310    0.345506  0.000000  \n",
       "2935    BGQNNVRTDH   0.000000    0.759362  0.796839  \n",
       "2936    UNUSNTTYXR   0.832368    0.643658  0.796839  \n",
       "\n",
       "[2937 rows x 10 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_vars = cont_vars.reset_index(drop=True)\n",
    "cat_vars = cat_vars.reset_index(drop=True)\n",
    "data = pd.concat([cat_vars, cont_vars], axis=1)\n",
    "print(f\"Data cleansed and combined.\\nRows: {len(data)}\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data drift artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data_columns = list(data.columns)\n",
    "with open('./artifacts/columns_drift.json','w+') as f:           \n",
    "    json.dump(data_columns,f)\n",
    "    \n",
    "data.to_csv('./artifacts/training_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binning object columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lead_id', 'lead_indicator', 'date_part', 'source', 'customer_group',\n",
       "       'onboarding', 'customer_code', 'purchases', 'time_spent', 'n_visits'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['bin_source'] = data['source']\n",
    "values_list = ['li', 'organic','signup','fb']\n",
    "data.loc[~data['source'].isin(values_list),'bin_source'] = 'Others'\n",
    "mapping = {'li' : 'socials', \n",
    "           'fb' : 'socials', \n",
    "           'organic': 'group1', \n",
    "           'signup': 'group1'\n",
    "           }\n",
    "\n",
    "data['bin_source'] = data['source'].map(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save gold medallion dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.sql(f\"drop table if exists train_gold\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_gold = spark.createDataFrame(data)\n",
    "# data_gold.write.saveAsTable('train_gold')\n",
    "# dbutils.notebook.exit(('training_golden_data',most_recent_date))\n",
    "\n",
    "data.to_csv('./artifacts/train_data_gold.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TRAINING\n",
    "\n",
    "Training the model uses a training dataset for training an ML algorithm. It has sample output data and the matching input data that affects the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Constants used:\n",
    "current_date = datetime.datetime.now().strftime(\"%Y_%B_%d\")\n",
    "data_gold_path = \"./artifacts/train_data_gold.csv\"\n",
    "data_version = \"00000\"\n",
    "experiment_name = current_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create paths\n",
    "\n",
    "Maybe the artifacts path has not been created during data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "#os.makedirs(\"artifacts\", exist_ok=True)\n",
    "os.makedirs(\"mlruns\", exist_ok=True)\n",
    "os.makedirs(\"mlruns/.trash\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 08:49:26 INFO mlflow.tracking.fluent: Experiment with name '2025_December_01' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/yasminebenmessaoud/Library/CloudStorage/OneDrive-ITU/5.%20Semester/Data%20Science%20in%20Production%20-%20MLOps%20and%20Software%20Engineering/itu-sdse-project/notebooks/mlruns/627272652637156136', creation_time=1764575366223, experiment_id='627272652637156136', last_update_time=1764575366223, lifecycle_stage='active', name='2025_December_01', tags={}>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions\n",
    "\n",
    "* *create_dummies*: Create one-hot encoding columns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy_cols(df, col):\n",
    "    df_dummies = pd.get_dummies(df[col], prefix=col, drop_first=True)\n",
    "    new_df = pd.concat([df, df_dummies], axis=1)\n",
    "    new_df = new_df.drop(col, axis=1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training data\n",
    "We use the training data we cleaned earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data length: 2937\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_id</th>\n",
       "      <th>lead_indicator</th>\n",
       "      <th>date_part</th>\n",
       "      <th>source</th>\n",
       "      <th>customer_group</th>\n",
       "      <th>onboarding</th>\n",
       "      <th>customer_code</th>\n",
       "      <th>purchases</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>n_visits</th>\n",
       "      <th>bin_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-01-27</td>\n",
       "      <td>signup</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>STWPXVNOWA</td>\n",
       "      <td>0.271612</td>\n",
       "      <td>0.512086</td>\n",
       "      <td>0.703093</td>\n",
       "      <td>group1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-11</td>\n",
       "      <td>signup</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>JWLXPVANUM</td>\n",
       "      <td>0.832368</td>\n",
       "      <td>0.648330</td>\n",
       "      <td>0.140619</td>\n",
       "      <td>group1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>signup</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>WNKCTHUHYI</td>\n",
       "      <td>0.608065</td>\n",
       "      <td>0.166620</td>\n",
       "      <td>0.187492</td>\n",
       "      <td>group1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-01-07</td>\n",
       "      <td>signup</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>INIQMTGGOO</td>\n",
       "      <td>0.495914</td>\n",
       "      <td>0.674776</td>\n",
       "      <td>0.328110</td>\n",
       "      <td>group1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-20</td>\n",
       "      <td>signup</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>SJGDAANOYJ</td>\n",
       "      <td>0.271612</td>\n",
       "      <td>0.366288</td>\n",
       "      <td>0.890585</td>\n",
       "      <td>group1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lead_id  lead_indicator   date_part  source  customer_group  onboarding  \\\n",
       "0        2             1.0  2024-01-27  signup               5       False   \n",
       "1       10             0.0  2024-01-11  signup               4        True   \n",
       "2       13             0.0  2024-01-22  signup               6        True   \n",
       "3       17             1.0  2024-01-07  signup               8       False   \n",
       "4       19             0.0  2024-01-20  signup               9        True   \n",
       "\n",
       "  customer_code  purchases  time_spent  n_visits bin_source  \n",
       "0    STWPXVNOWA   0.271612    0.512086  0.703093     group1  \n",
       "1    JWLXPVANUM   0.832368    0.648330  0.140619     group1  \n",
       "2    WNKCTHUHYI   0.608065    0.166620  0.187492     group1  \n",
       "3    INIQMTGGOO   0.495914    0.674776  0.328110     group1  \n",
       "4    SJGDAANOYJ   0.271612    0.366288  0.890585     group1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_gold_path)\n",
    "print(f\"Training data length: {len(data)}\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data type split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"lead_id\", \"customer_code\", \"date_part\"], axis=1)\n",
    "\n",
    "cat_cols = [\"customer_group\", \"onboarding\", \"bin_source\", \"source\"]\n",
    "cat_vars = data[cat_cols]\n",
    "\n",
    "other_vars = data.drop(cat_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy variable for categorical vars\n",
    "\n",
    "1. Create one-hot encoded cols for cat vars\n",
    "2. Change to floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed column lead_indicator to float\n",
      "Changed column purchases to float\n",
      "Changed column time_spent to float\n",
      "Changed column n_visits to float\n",
      "Changed column customer_group_2 to float\n",
      "Changed column customer_group_3 to float\n",
      "Changed column customer_group_4 to float\n",
      "Changed column customer_group_5 to float\n",
      "Changed column customer_group_6 to float\n",
      "Changed column customer_group_7 to float\n",
      "Changed column customer_group_8 to float\n",
      "Changed column customer_group_9 to float\n",
      "Changed column onboarding_True to float\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/8sx16ndx5ds22xjw_x_3lzyh0000gn/T/ipykernel_22314/3358702209.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat_vars[col] = cat_vars[col].astype(\"category\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for col in cat_vars:\n",
    "    cat_vars[col] = cat_vars[col].astype(\"category\")\n",
    "    cat_vars = create_dummy_cols(cat_vars, col)\n",
    "\n",
    "data = pd.concat([other_vars, cat_vars], axis=1)\n",
    "\n",
    "for col in data:\n",
    "    data[col] = data[col].astype(\"float64\")\n",
    "    print(f\"Changed column {col} to float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"lead_indicator\"]\n",
    "X = data.drop([\"lead_indicator\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335     1.0\n",
       "499     0.0\n",
       "2850    1.0\n",
       "2142    0.0\n",
       "1019    0.0\n",
       "       ... \n",
       "1378    0.0\n",
       "2771    0.0\n",
       "28      0.0\n",
       "1410    1.0\n",
       "2488    1.0\n",
       "Name: lead_indicator, Length: 2496, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42, test_size=0.15, stratify=y\n",
    ")\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "This stage involves training the ML algorithm by providing it with datasets, where the learning process takes place. Consistent training can significantly enhance the model's prediction accuracy. It's essential to initialize the model's weights randomly so the algorithm can effectively learn to adjust them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m==>\u001b[0m \u001b[1mAuto-updating Homebrew...\u001b[0m\n",
      "Adjust how often this is run with `$HOMEBREW_AUTO_UPDATE_SECS` or disable with\n",
      "`$HOMEBREW_NO_AUTO_UPDATE=1`. Hide these hints with `$HOMEBREW_NO_ENV_HINTS=1` (see `man brew`).\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/portable-ruby/blobs/sha256:c6946ba2c387b47934e77c352c2056489421003ec7ddb2abf246cef2168ec140\u001b[0m\n",
      "######################################################################### 100.0%###########################                      73.7%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring portable-ruby-3.4.7.arm64_big_sur.bottle.tar.gz\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mAuto-updated Homebrew!\u001b[0m\n",
      "Updated 2 taps (homebrew/core and homebrew/cask).\n",
      "\u001b[34m==>\u001b[0m \u001b[1mNew Formulae\u001b[0m\n",
      "aklomp-base64: Fast Base64 stream encoder/decoder in C99, with SIMD acceleration\n",
      "ansible@12: Automate deployment, configuration, and upgrading\n",
      "auto-editor: Efficient media analysis and rendering\n",
      "aws-spiffe-workload-helper: Helper for providing AWS credentials to workloads using their SPIFFE identity\n",
      "bulletty: Pretty feed reader (ATOM/RSS) that stores articles in Markdown files\n",
      "claude-code-templates: CLI tool for configuring and monitoring Claude Code\n",
      "container: Create and run Linux containers using lightweight virtual machines\n",
      "corepack: Package acting as bridge between Node projects and their package managers\n",
      "devcockpit: TUI system monitor for Apple Silicon\n",
      "diffnav: Git diff pager based on delta but with a file tree\n",
      "doh: Stand-alone DNS-over-HTTPS resolver using libcurl\n",
      "e1s: TUI for managing AWS ECS, inspired by k9s\n",
      "fake-gcs-server: Emulator for Google Cloud Storage API\n",
      "faketty: Wrapper to exec a command in a pty, even if redirecting the output\n",
      "fastrace: Dependency-free traceroute implementation in pure C\n",
      "fnox: Fort Knox for your secrets - flexible secret management tool\n",
      "forgejo-cli: CLI tool for interacting with Forgejo\n",
      "git-xet: Git LFS plugin that uploads and downloads using the Xet protocol\n",
      "gitlogue: Cinematic Git commit replay tool\n",
      "gitnr: Create `.gitignore` using templates from TopTal, GitHub or your own collection\n",
      "gotun: Lightweight HTTP proxy over SSH\n",
      "gruyere: TUI program for viewing and killing processes listening on ports\n",
      "gwctl: CLI for managing and inspecting Gateway API resources in Kubernetes clusters\n",
      "hapless: Run and manage background processes\n",
      "helm@3: Kubernetes package manager\n",
      "hexhog: Hex viewer/editor\n",
      "hf-mcp-server: MCP Server for Hugging Face\n",
      "icu4c@78: C/C++ and Java libraries for Unicode and globalization\n",
      "install-nothing: Simulates installing things but doesn't actually install anything\n",
      "intelli-shell: Like IntelliSense, but for shells\n",
      "joyce: Emulates the Amstrad PCW on Unix, Windows and macOS\n",
      "kagent: Kubernetes native framework for building AI agents\n",
      "kanata-tray: System tray for kanata keyboard remapper\n",
      "ktea: Kafka TUI client\n",
      "libaegis: Portable C implementations of the AEGIS family of encryption algorithms\n",
      "libdecor: Client-side decorations library for Wayland client\n",
      "magika: Fast and accurate AI powered file content types detection\n",
      "maigret: Collect a dossier on a person by username from thousands of sites\n",
      "mail-deduplicate: CLI to deduplicate mails from mail boxes\n",
      "mark: Sync your markdown files with Confluence pages\n",
      "mbedtls@3: Cryptographic & SSL/TLS library\n",
      "mcat: Terminal image, video, directory, and Markdown viewer\n",
      "mdfried: Terminal markdown viewer\n",
      "mitama-cpp-result: Provides `result<T, E>` and `maybe<T>` and monadic functions for them\n",
      "mysql-to-sqlite3: Transfer data from MySQL to SQLite\n",
      "openlist: New AList fork addressing anti-trust issues\n",
      "openssl@1.1: Cryptography and SSL/TLS Toolkit\n",
      "parqeye: Peek inside Parquet files right from your terminal\n",
      "php@8.4: General-purpose scripting language\n",
      "pipewire: Server and user space API to deal with multimedia pipelines\n",
      "py7zr: 7-zip in Python\n",
      "qqqa: Fast, stateless LLM for your shell: qq answers; qa runs commands\n",
      "rails-mcp-server: MCP server for Rails applications\n",
      "reddix: Reddit, refined for the terminal\n",
      "redis@8.2: Persistent key-value database, with built-in net interface\n",
      "resterm: Terminal client for .http/.rest files with HTTP, GraphQL, and gRPC support\n",
      "rumdl: Markdown Linter and Formatter written in Rust\n",
      "spiffe-helper: Tool that can be used to retrieve and manage SVIDs on behalf of a workload\n",
      "sqlite3-to-mysql: Transfer data from SQLite to MySQL\n",
      "strands-agents-sops: Standard Operating Procedures for AI agents using natural language\n",
      "thorvg: Lightweight portable library used for drawing vector-based scenes and animations\n",
      "toktop: LLM usage monitor in terminal\n",
      "torrra: Find and download torrents without leaving your CLI\n",
      "treemd: TUI and CLI dual pane markdown viewer\n",
      "ts_query_ls: LSP implementation for Tree-sitter's query files\n",
      "tscriptify: Golang struct to TypeScript class/interface converter\n",
      "tuios: Terminal UI OS (Terminal Multiplexer)\n",
      "vibecheck: AI-powered git commit assistant written in Go\n",
      "xcp: Fast & lightweight command-line tool for managing Xcode projects, built in Swift\n",
      "xleak: Terminal Excel viewer with an interactive TUI\n",
      "\u001b[34m==>\u001b[0m \u001b[1mNew Casks\u001b[0m\n",
      "airscroll: Smooth mouse scrolling utility\n",
      "aks-desktop: Azure Kubernetes Service desktop application\n",
      "antigravity: AI Coding Agent IDE\n",
      "ape: Software for DNA sequence analysis and annotation\n",
      "appbox: iOS app distribution tool\n",
      "athas: Lightweight code editor\n",
      "butterkit: App Store screenshots editor\n",
      "cadreader: CAD drawing viewer\n",
      "chatglm: Desktop client for the ChatGLM AI chatbot\n",
      "chitubox: 3D printing slicer software\n",
      "daruma: Track your goals using the Daruma Method\n",
      "disk-jockey: Disk image creator and analyser for retro computers or emulators\n",
      "djstudio@next: DAW for DJs\n",
      "dotnet-sdk@9: Developer platform\n",
      "filo: AI-powered email client designed for Gmail\n",
      "font-amarna\n",
      "font-geom\n",
      "font-gveret-levin\n",
      "font-line-seed-jp\n",
      "font-myna\n",
      "font-psudofont-liga-mono\n",
      "font-sekuya\n",
      "font-urw-core35\n",
      "fontra-pak: Browser-based font editor\n",
      "freepdf: Reader that supports translating PDF documents\n",
      "freetex: Free intelligent formula recognition software\n",
      "hyperwhisper: AI-powered speech-to-text transcription\n",
      "karing: Proxy utility\n",
      "kimi: AI chat assistant from Moonshot\n",
      "locu: Daily planner and focus timer\n",
      "meituxiuxiu: Photo editing and beautification software\n",
      "motionik: Screen recording software\n",
      "mountmate: Menubar app to easily manage external drives\n",
      "mozregression-gui: Interactive regression range finder for Firefox and other Mozilla products\n",
      "nkoda: Digital sheet music app\n",
      "notepadexe: Lightweight code editor\n",
      "okta-verify: Identity verification provider\n",
      "pot: Software for text translation and recognition\n",
      "qianwen: AI assistant and chatbot powered by Alibaba's Qwen model\n",
      "qidistudio: Slicer software for QIDI 3D printers\n",
      "qqnews: Tencent News client\n",
      "rocketman-choices-packager: Utility for customising installer package choices\n",
      "shell360: Cross-platform SSH & SFTP client\n",
      "simplysign: Emulates a physical crypto card/reader for proCertum SmartSign\n",
      "sodamusic: Music app\n",
      "stirling-pdf: PDF utility\n",
      "stremio@beta: Open-source media center\n",
      "taobao: Online Shopping Client\n",
      "vocaster-hub: Interface controller for Focusrite Vocaster One and Two\n",
      "white-rabbit: SVG utility and optimiser\n",
      "whodb: Database management tool with AI-powered features\n",
      "wiso-steuer-2026: Tax declaration for the fiscal year 2025\n",
      "wootility: Configuration software for Wooting keyboards\n",
      "xmlmind-editor: Strictly validating near WYSIWYG XML editor\n",
      "zo: Friendly personal server\n",
      "\n",
      "You have \u001b[1m57\u001b[0m outdated formulae and \u001b[1m2\u001b[0m outdated casks installed.\n",
      "\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching downloads for: \u001b[32mlibomp\u001b[39m\u001b[0m\n",
      "\u001b[?25l\u001b[K\u001b[34m⠋\u001b[0m Bottle Manifest libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠋\u001b[0m Bottle Manifest libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠙\u001b[0m Bottle Manifest libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠙\u001b[0m Bottle Manifest libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠚\u001b[0m Bottle Manifest libomp (21.1.6)\u001b[0G\u001b[K\u001b[32m✔︎\u001b[0m Bottle Manifest libomp (21.1.6)                  [Downloaded   11.9KB/ 11.9KB]\n",
      "\u001b[?25h\u001b[?25l\u001b[K\u001b[34m⠞\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠞\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠖\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠖\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠦\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠦\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠴\u001b[0m Bottle libomp (21.1.6)                           [Downloading 225.3KB/586.4KB]\u001b[0G\u001b[K\u001b[34m⠴\u001b[0m Bottle libomp (21.1.6)                           [Extracting  586.4KB/586.4KB]\u001b[0G\u001b[K\u001b[32m✔︎\u001b[0m Bottle libomp (21.1.6)                           [Downloaded  586.4KB/586.4KB]\n",
      "\u001b[?25h\u001b[34m==>\u001b[0m \u001b[1mPouring libomp--21.1.6.arm64_sequoia.bottle.tar.gz\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mCaveats\u001b[0m\n",
      "libomp is keg-only, which means it was not symlinked into /opt/homebrew,\n",
      "because it can override GCC headers and result in broken builds.\n",
      "\n",
      "For compilers to find libomp you may need to set:\n",
      "  export LDFLAGS=\"-L/opt/homebrew/opt/libomp/lib\"\n",
      "  export CPPFLAGS=\"-I/opt/homebrew/opt/libomp/include\"\n",
      "\u001b[34m==>\u001b[0m \u001b[1mSummary\u001b[0m\n",
      "🍺  /opt/homebrew/Cellar/libomp/21.1.6: 9 files, 1.8MB\n",
      "\u001b[34m==>\u001b[0m \u001b[1mRunning `brew cleanup libomp`...\u001b[0m\n",
      "Disable this behaviour by setting `HOMEBREW_NO_INSTALL_CLEANUP=1`.\n",
      "Hide these hints with `HOMEBREW_NO_ENV_HINTS=1` (see `man brew`).\n"
     ]
    }
   ],
   "source": [
    "!brew install libomp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.1.2-py3-none-macosx_12_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting numpy (from xgboost)\n",
      "  Using cached numpy-2.3.5-cp311-cp311-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting scipy (from xgboost)\n",
      "  Using cached scipy-1.16.3-cp311-cp311-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Downloading xgboost-3.1.2-py3-none-macosx_12_0_arm64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached numpy-2.3.5-cp311-cp311-macosx_14_0_arm64.whl (5.4 MB)\n",
      "Using cached scipy-1.16.3-cp311-cp311-macosx_14_0_arm64.whl (20.9 MB)\n",
      "Installing collected packages: numpy, scipy, xgboost\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 2.3.5\n",
      "\u001b[2K    Uninstalling numpy-2.3.5:\n",
      "\u001b[2K      Successfully uninstalled numpy-2.3.5\n",
      "\u001b[2K  Attempting uninstall: scipy━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/3\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: scipy 1.16.3[0m \u001b[32m0/3\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling scipy-1.16.3:╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [scipy]\n",
      "\u001b[2K      Successfully uninstalled scipy-1.16.3━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [scipy]\n",
      "\u001b[2K  Attempting uninstall: xgboost\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [scipy]\n",
      "\u001b[2K    Found existing installation: xgboost 2.1.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [scipy]\n",
      "\u001b[2K    Uninstalling xgboost-2.1.1:\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [scipy]\n",
      "\u001b[2K      Successfully uninstalled xgboost-2.1.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [scipy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [xgboost]m2/3\u001b[0m [xgboost]\n",
      "\u001b[1A\u001b[2KSuccessfully installed numpy-2.3.5 scipy-1.16.3 xgboost-3.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost==1.7.6\n",
      "  Downloading xgboost-1.7.6-py3-none-macosx_12_0_arm64.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: numpy in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from xgboost==1.7.6) (2.3.5)\n",
      "Requirement already satisfied: scipy in /Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages (from xgboost==1.7.6) (1.16.3)\n",
      "Downloading xgboost-1.7.6-py3-none-macosx_12_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xgboost\n",
      "  Attempting uninstall: xgboost\n",
      "    Found existing installation: xgboost 3.1.2\n",
      "    Uninstalling xgboost-3.1.2:\n",
      "      Successfully uninstalled xgboost-3.1.2\n",
      "Successfully installed xgboost-1.7.6\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost==1.7.6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[CV 4/10] END eval_metric=aucpr, learning_rate=0.05299176412941538, max_depth=7, min_split_loss=3.3081182713192603, objective=reg:squarederror, subsample=0.10405445120797607;, score=0.532 total time=   0.0s\n",
      "[CV 3/10] END eval_metric=aucpr, learning_rate=0.05299176412941538, max_depth=7, min_split_loss=3.3081182713192603, objective=reg:squarederror, subsample=0.10405445120797607;, score=0.532 total time=   0.1s\n",
      "[CV 1/10] END eval_metric=aucpr, learning_rate=0.05299176412941538, max_depth=7, min_split_loss=3.3081182713192603, objective=reg:squarederror, subsample=0.10405445120797607;, score=0.532 total time=   0.1s\n",
      "[CV 2/10] END eval_metric=aucpr, learning_rate=0.05299176412941538, max_depth=7, min_split_loss=3.3081182713192603, objective=reg:squarederror, subsample=0.10405445120797607;, score=0.532 total time=   0.1s\n",
      "[CV 5/10] END eval_metric=aucpr, learning_rate=0.05299176412941538, max_depth=7, min_split_loss=3.3081182713192603, objective=reg:squarederror, subsample=0.10405445120797607;, score=0.532 total time=   0.1s\n",
      "[CV 9/10] END eval_metric=aucpr, learning_rate=0.05299176412941538, max_depth=7, min_split_loss=3.3081182713192603, objective=reg:squarederror, subsample=0.10405445120797607;, score=0.530 total time=   0.0s\n",
      "[CV 6/10] END eval_metric=aucpr, learning_rate=0.05299176412941538, max_depth=7, min_split_loss=3.3081182713192603, objective=reg:squarederror, subsample=0.10405445120797607;, score=0.532 total time=   0.0s\n",
      "[CV 7/10] END eval_metric=aucpr, learning_rate=0.05299176412941538, max_depth=7, min_split_loss=3.3081182713192603, objective=reg:squarederror, subsample=0.10405445120797607;, score=0.530 total time=   0.0s\n",
      "[CV 1/10] END eval_metric=aucpr, learning_rate=0.08743112003591047, max_depth=3, min_split_loss=6.1184087076480465, objective=binary:logistic, subsample=0.22904694074509424;, score=0.532 total time=   0.0s\n",
      "[CV 8/10] END eval_metric=aucpr, learning_rate=0.05299176412941538, max_depth=7, min_split_loss=3.3081182713192603, objective=reg:squarederror, subsample=0.10405445120797607;, score=0.530 total time=   0.0s\n",
      "[CV 2/10] END eval_metric=aucpr, learning_rate=0.08743112003591047, max_depth=3, min_split_loss=6.1184087076480465, objective=binary:logistic, subsample=0.22904694074509424;, score=0.532 total time=   0.0s\n",
      "[CV 10/10] END eval_metric=aucpr, learning_rate=0.05299176412941538, max_depth=7, min_split_loss=3.3081182713192603, objective=reg:squarederror, subsample=0.10405445120797607;, score=0.534 total time=   0.0s\n",
      "[CV 3/10] END eval_metric=aucpr, learning_rate=0.08743112003591047, max_depth=3, min_split_loss=6.1184087076480465, objective=binary:logistic, subsample=0.22904694074509424;, score=0.532 total time=   0.0s\n",
      "[CV 4/10] END eval_metric=aucpr, learning_rate=0.08743112003591047, max_depth=3, min_split_loss=6.1184087076480465, objective=binary:logistic, subsample=0.22904694074509424;, score=0.532 total time=   0.0s\n",
      "[CV 5/10] END eval_metric=aucpr, learning_rate=0.08743112003591047, max_depth=3, min_split_loss=6.1184087076480465, objective=binary:logistic, subsample=0.22904694074509424;, score=0.532 total time=   0.0s\n",
      "[CV 6/10] END eval_metric=aucpr, learning_rate=0.08743112003591047, max_depth=3, min_split_loss=6.1184087076480465, objective=binary:logistic, subsample=0.22904694074509424;, score=0.532 total time=   0.0s\n",
      "[CV 7/10] END eval_metric=aucpr, learning_rate=0.08743112003591047, max_depth=3, min_split_loss=6.1184087076480465, objective=binary:logistic, subsample=0.22904694074509424;, score=0.530 total time=   0.0s\n",
      "[CV 9/10] END eval_metric=aucpr, learning_rate=0.08743112003591047, max_depth=3, min_split_loss=6.1184087076480465, objective=binary:logistic, subsample=0.22904694074509424;, score=0.530 total time=   0.0s\n",
      "[CV 1/10] END eval_metric=error, learning_rate=0.07350557519539544, max_depth=7, min_split_loss=6.402062465744756, objective=reg:squarederror, subsample=0.39724392441009826;, score=0.532 total time=   0.0s\n",
      "[CV 5/10] END eval_metric=error, learning_rate=0.07350557519539544, max_depth=7, min_split_loss=6.402062465744756, objective=reg:squarederror, subsample=0.39724392441009826;, score=0.532 total time=   0.0s\n",
      "[CV 8/10] END eval_metric=aucpr, learning_rate=0.08743112003591047, max_depth=3, min_split_loss=6.1184087076480465, objective=binary:logistic, subsample=0.22904694074509424;, score=0.530 total time=   0.0s\n",
      "[CV 9/10] END eval_metric=error, learning_rate=0.07350557519539544, max_depth=7, min_split_loss=6.402062465744756, objective=reg:squarederror, subsample=0.39724392441009826;, score=0.530 total time=   0.0s\n",
      "[CV 3/10] END eval_metric=error, learning_rate=0.07350557519539544, max_depth=7, min_split_loss=6.402062465744756, objective=reg:squarederror, subsample=0.39724392441009826;, score=0.532 total time=   0.0s\n",
      "[CV 2/10] END eval_metric=error, learning_rate=0.07350557519539544, max_depth=7, min_split_loss=6.402062465744756, objective=reg:squarederror, subsample=0.39724392441009826;, score=0.532 total time=   0.0s\n",
      "[CV 10/10] END eval_metric=error, learning_rate=0.07350557519539544, max_depth=7, min_split_loss=6.402062465744756, objective=reg:squarederror, subsample=0.39724392441009826;, score=0.534 total time=   0.0s\n",
      "[CV 10/10] END eval_metric=aucpr, learning_rate=0.08743112003591047, max_depth=3, min_split_loss=6.1184087076480465, objective=binary:logistic, subsample=0.22904694074509424;, score=0.534 total time=   0.0s\n",
      "[CV 7/10] END eval_metric=error, learning_rate=0.07350557519539544, max_depth=7, min_split_loss=6.402062465744756, objective=reg:squarederror, subsample=0.39724392441009826;, score=0.530 total time=   0.0s\n",
      "[CV 6/10] END eval_metric=error, learning_rate=0.07350557519539544, max_depth=7, min_split_loss=6.402062465744756, objective=reg:squarederror, subsample=0.39724392441009826;, score=0.532 total time=   0.0s\n",
      "[CV 4/10] END eval_metric=error, learning_rate=0.07350557519539544, max_depth=7, min_split_loss=6.402062465744756, objective=reg:squarederror, subsample=0.39724392441009826;, score=0.532 total time=   0.0s\n",
      "[CV 1/10] END eval_metric=aucpr, learning_rate=0.13427502654785317, max_depth=7, min_split_loss=4.330606637651863, objective=binary:logistic, subsample=0.3422057629359939;, score=0.784 total time=   0.0s\n",
      "[CV 8/10] END eval_metric=error, learning_rate=0.07350557519539544, max_depth=7, min_split_loss=6.402062465744756, objective=reg:squarederror, subsample=0.39724392441009826;, score=0.530 total time=   0.0s\n",
      "[CV 3/10] END eval_metric=aucpr, learning_rate=0.13427502654785317, max_depth=7, min_split_loss=4.330606637651863, objective=binary:logistic, subsample=0.3422057629359939;, score=0.792 total time=   0.0s\n",
      "[CV 5/10] END eval_metric=aucpr, learning_rate=0.13427502654785317, max_depth=7, min_split_loss=4.330606637651863, objective=binary:logistic, subsample=0.3422057629359939;, score=0.800 total time=   0.0s\n",
      "[CV 9/10] END eval_metric=aucpr, learning_rate=0.13427502654785317, max_depth=7, min_split_loss=4.330606637651863, objective=binary:logistic, subsample=0.3422057629359939;, score=0.755 total time=   0.0s\n",
      "[CV 3/10] END eval_metric=aucpr, learning_rate=0.09746381931063475, max_depth=5, min_split_loss=4.570723380296791, objective=reg:logistic, subsample=0.8471794446423964;, score=0.532 total time=   0.0s\n",
      "[CV 7/10] END eval_metric=aucpr, learning_rate=0.13427502654785317, max_depth=7, min_split_loss=4.330606637651863, objective=binary:logistic, subsample=0.3422057629359939;, score=0.799 total time=   0.0s\n",
      "[CV 1/10] END eval_metric=aucpr, learning_rate=0.09746381931063475, max_depth=5, min_split_loss=4.570723380296791, objective=reg:logistic, subsample=0.8471794446423964;, score=0.532 total time=   0.0s\n",
      "[CV 5/10] END eval_metric=aucpr, learning_rate=0.09746381931063475, max_depth=5, min_split_loss=4.570723380296791, objective=reg:logistic, subsample=0.8471794446423964;, score=0.532 total time=   0.0s\n",
      "[CV 4/10] END eval_metric=aucpr, learning_rate=0.13427502654785317, max_depth=7, min_split_loss=4.330606637651863, objective=binary:logistic, subsample=0.3422057629359939;, score=0.768 total time=   0.0s\n",
      "[CV 6/10] END eval_metric=aucpr, learning_rate=0.13427502654785317, max_depth=7, min_split_loss=4.330606637651863, objective=binary:logistic, subsample=0.3422057629359939;, score=0.796 total time=   0.0s\n",
      "[CV 2/10] END eval_metric=aucpr, learning_rate=0.13427502654785317, max_depth=7, min_split_loss=4.330606637651863, objective=binary:logistic, subsample=0.3422057629359939;, score=0.792 total time=   0.0s\n",
      "[CV 10/10] END eval_metric=aucpr, learning_rate=0.13427502654785317, max_depth=7, min_split_loss=4.330606637651863, objective=binary:logistic, subsample=0.3422057629359939;, score=0.811 total time=   0.0s\n",
      "[CV 4/10] END eval_metric=aucpr, learning_rate=0.09746381931063475, max_depth=5, min_split_loss=4.570723380296791, objective=reg:logistic, subsample=0.8471794446423964;, score=0.728 total time=   0.0s\n",
      "[CV 8/10] END eval_metric=aucpr, learning_rate=0.13427502654785317, max_depth=7, min_split_loss=4.330606637651863, objective=binary:logistic, subsample=0.3422057629359939;, score=0.763 total time=   0.0s\n",
      "[CV 3/10] END eval_metric=aucpr, learning_rate=0.10473764050951145, max_depth=4, min_split_loss=9.629733106424132, objective=reg:logistic, subsample=0.6654203848495834;, score=0.532 total time=   0.0s\n",
      "[CV 7/10] END eval_metric=aucpr, learning_rate=0.09746381931063475, max_depth=5, min_split_loss=4.570723380296791, objective=reg:logistic, subsample=0.8471794446423964;, score=0.550 total time=   0.0s\n",
      "[CV 2/10] END eval_metric=aucpr, learning_rate=0.09746381931063475, max_depth=5, min_split_loss=4.570723380296791, objective=reg:logistic, subsample=0.8471794446423964;, score=0.680 total time=   0.0s\n",
      "[CV 1/10] END eval_metric=error, learning_rate=0.024916115232507665, max_depth=4, min_split_loss=8.181363823343188, objective=reg:squarederror, subsample=0.3823469373893422;, score=0.532 total time=   0.0s\n",
      "[CV 6/10] END eval_metric=aucpr, learning_rate=0.09746381931063475, max_depth=5, min_split_loss=4.570723380296791, objective=reg:logistic, subsample=0.8471794446423964;, score=0.760 total time=   0.0s\n",
      "[CV 9/10] END eval_metric=aucpr, learning_rate=0.09746381931063475, max_depth=5, min_split_loss=4.570723380296791, objective=reg:logistic, subsample=0.8471794446423964;, score=0.683 total time=   0.0s\n",
      "[CV 5/10] END eval_metric=error, learning_rate=0.024916115232507665, max_depth=4, min_split_loss=8.181363823343188, objective=reg:squarederror, subsample=0.3823469373893422;, score=0.532 total time=   0.0s\n",
      "[CV 7/10] END eval_metric=aucpr, learning_rate=0.10473764050951145, max_depth=4, min_split_loss=9.629733106424132, objective=reg:logistic, subsample=0.6654203848495834;, score=0.530 total time=   0.0s\n",
      "[CV 9/10] END eval_metric=error, learning_rate=0.024916115232507665, max_depth=4, min_split_loss=8.181363823343188, objective=reg:squarederror, subsample=0.3823469373893422;, score=0.530 total time=   0.0s\n",
      "[CV 4/10] END eval_metric=aucpr, learning_rate=0.10473764050951145, max_depth=4, min_split_loss=9.629733106424132, objective=reg:logistic, subsample=0.6654203848495834;, score=0.532 total time=   0.0s\n",
      "[CV 2/10] END eval_metric=error, learning_rate=0.024916115232507665, max_depth=4, min_split_loss=8.181363823343188, objective=reg:squarederror, subsample=0.3823469373893422;, score=0.532 total time=   0.0s\n",
      "[CV 8/10] END eval_metric=aucpr, learning_rate=0.09746381931063475, max_depth=5, min_split_loss=4.570723380296791, objective=reg:logistic, subsample=0.8471794446423964;, score=0.530 total time=   0.0s\n",
      "[CV 6/10] END eval_metric=error, learning_rate=0.024916115232507665, max_depth=4, min_split_loss=8.181363823343188, objective=reg:squarederror, subsample=0.3823469373893422;, score=0.532 total time=   0.0s\n",
      "[CV 10/10] END eval_metric=aucpr, learning_rate=0.09746381931063475, max_depth=5, min_split_loss=4.570723380296791, objective=reg:logistic, subsample=0.8471794446423964;, score=0.534 total time=   0.0s\n",
      "[CV 10/10] END eval_metric=error, learning_rate=0.024916115232507665, max_depth=4, min_split_loss=8.181363823343188, objective=reg:squarederror, subsample=0.3823469373893422;, score=0.534 total time=   0.0s\n",
      "[CV 3/10] END eval_metric=error, learning_rate=0.24517995936765524, max_depth=6, min_split_loss=2.5253349437857056, objective=binary:logistic, subsample=0.6575111505357728;, score=0.844 total time=   0.0s\n",
      "[CV 3/10] END eval_metric=error, learning_rate=0.024916115232507665, max_depth=4, min_split_loss=8.181363823343188, objective=reg:squarederror, subsample=0.3823469373893422;, score=0.532 total time=   0.0s\n",
      "[CV 5/10] END eval_metric=aucpr, learning_rate=0.10473764050951145, max_depth=4, min_split_loss=9.629733106424132, objective=reg:logistic, subsample=0.6654203848495834;, score=0.532 total time=   0.0s\n",
      "[CV 8/10] END eval_metric=aucpr, learning_rate=0.10473764050951145, max_depth=4, min_split_loss=9.629733106424132, objective=reg:logistic, subsample=0.6654203848495834;, score=0.530 total time=   0.0s\n",
      "[CV 1/10] END eval_metric=aucpr, learning_rate=0.10473764050951145, max_depth=4, min_split_loss=9.629733106424132, objective=reg:logistic, subsample=0.6654203848495834;, score=0.532 total time=   0.0s\n",
      "[CV 7/10] END eval_metric=error, learning_rate=0.024916115232507665, max_depth=4, min_split_loss=8.181363823343188, objective=reg:squarederror, subsample=0.3823469373893422;, score=0.530 total time=   0.0s\n",
      "[CV 4/10] END eval_metric=error, learning_rate=0.024916115232507665, max_depth=4, min_split_loss=8.181363823343188, objective=reg:squarederror, subsample=0.3823469373893422;, score=0.532 total time=   0.0s\n",
      "[CV 6/10] END eval_metric=aucpr, learning_rate=0.10473764050951145, max_depth=4, min_split_loss=9.629733106424132, objective=reg:logistic, subsample=0.6654203848495834;, score=0.532 total time=   0.0s\n",
      "[CV 9/10] END eval_metric=aucpr, learning_rate=0.10473764050951145, max_depth=4, min_split_loss=9.629733106424132, objective=reg:logistic, subsample=0.6654203848495834;, score=0.530 total time=   0.0s\n",
      "[CV 2/10] END eval_metric=aucpr, learning_rate=0.10473764050951145, max_depth=4, min_split_loss=9.629733106424132, objective=reg:logistic, subsample=0.6654203848495834;, score=0.532 total time=   0.0s\n",
      "[CV 8/10] END eval_metric=error, learning_rate=0.024916115232507665, max_depth=4, min_split_loss=8.181363823343188, objective=reg:squarederror, subsample=0.3823469373893422;, score=0.530 total time=   0.0s\n",
      "[CV 7/10] END eval_metric=error, learning_rate=0.24517995936765524, max_depth=6, min_split_loss=2.5253349437857056, objective=binary:logistic, subsample=0.6575111505357728;, score=0.835 total time=   0.1s\n",
      "[CV 1/10] END eval_metric=error, learning_rate=0.24517995936765524, max_depth=6, min_split_loss=2.5253349437857056, objective=binary:logistic, subsample=0.6575111505357728;, score=0.796 total time=   0.0s\n",
      "[CV 10/10] END eval_metric=aucpr, learning_rate=0.10473764050951145, max_depth=4, min_split_loss=9.629733106424132, objective=reg:logistic, subsample=0.6654203848495834;, score=0.534 total time=   0.0s\n",
      "[CV 4/10] END eval_metric=error, learning_rate=0.24517995936765524, max_depth=6, min_split_loss=2.5253349437857056, objective=binary:logistic, subsample=0.6575111505357728;, score=0.808 total time=   0.0s\n",
      "[CV 1/10] END eval_metric=error, learning_rate=0.3059083565755502, max_depth=7, min_split_loss=1.9772306696894415, objective=reg:logistic, subsample=0.1554404750389139;, score=0.808 total time=   0.0s\n",
      "[CV 8/10] END eval_metric=error, learning_rate=0.24517995936765524, max_depth=6, min_split_loss=2.5253349437857056, objective=binary:logistic, subsample=0.6575111505357728;, score=0.787 total time=   0.0s\n",
      "[CV 2/10] END eval_metric=error, learning_rate=0.3059083565755502, max_depth=7, min_split_loss=1.9772306696894415, objective=reg:logistic, subsample=0.1554404750389139;, score=0.804 total time=   0.0s\n",
      "[CV 5/10] END eval_metric=error, learning_rate=0.3059083565755502, max_depth=7, min_split_loss=1.9772306696894415, objective=reg:logistic, subsample=0.1554404750389139;, score=0.784 total time=   0.0s\n",
      "[CV 4/10] END eval_metric=error, learning_rate=0.3059083565755502, max_depth=7, min_split_loss=1.9772306696894415, objective=reg:logistic, subsample=0.1554404750389139;, score=0.800 total time=   0.0s\n",
      "[CV 3/10] END eval_metric=error, learning_rate=0.3059083565755502, max_depth=7, min_split_loss=1.9772306696894415, objective=reg:logistic, subsample=0.1554404750389139;, score=0.836 total time=   0.0s\n",
      "[CV 2/10] END eval_metric=error, learning_rate=0.24517995936765524, max_depth=6, min_split_loss=2.5253349437857056, objective=binary:logistic, subsample=0.6575111505357728;, score=0.808 total time=   0.0s\n",
      "[CV 6/10] END eval_metric=error, learning_rate=0.3059083565755502, max_depth=7, min_split_loss=1.9772306696894415, objective=reg:logistic, subsample=0.1554404750389139;, score=0.812 total time=   0.0s\n",
      "[CV 5/10] END eval_metric=error, learning_rate=0.24517995936765524, max_depth=6, min_split_loss=2.5253349437857056, objective=binary:logistic, subsample=0.6575111505357728;, score=0.796 total time=   0.0s\n",
      "[CV 7/10] END eval_metric=error, learning_rate=0.3059083565755502, max_depth=7, min_split_loss=1.9772306696894415, objective=reg:logistic, subsample=0.1554404750389139;, score=0.835 total time=   0.0s\n",
      "[CV 2/10] END eval_metric=error, learning_rate=0.19738321461148345, max_depth=9, min_split_loss=6.291786728306978, objective=binary:logistic, subsample=0.18204693546324435;, score=0.800 total time=   0.0s\n",
      "[CV 1/10] END eval_metric=error, learning_rate=0.19738321461148345, max_depth=9, min_split_loss=6.291786728306978, objective=binary:logistic, subsample=0.18204693546324435;, score=0.808 total time=   0.0s\n",
      "[CV 9/10] END eval_metric=error, learning_rate=0.3059083565755502, max_depth=7, min_split_loss=1.9772306696894415, objective=reg:logistic, subsample=0.1554404750389139;, score=0.779 total time=   0.0s\n",
      "[CV 9/10] END eval_metric=error, learning_rate=0.24517995936765524, max_depth=6, min_split_loss=2.5253349437857056, objective=binary:logistic, subsample=0.6575111505357728;, score=0.771 total time=   0.0s\n",
      "[CV 10/10] END eval_metric=error, learning_rate=0.3059083565755502, max_depth=7, min_split_loss=1.9772306696894415, objective=reg:logistic, subsample=0.1554404750389139;, score=0.831 total time=   0.0s\n",
      "[CV 6/10] END eval_metric=error, learning_rate=0.24517995936765524, max_depth=6, min_split_loss=2.5253349437857056, objective=binary:logistic, subsample=0.6575111505357728;, score=0.820 total time=   0.0s\n",
      "[CV 5/10] END eval_metric=error, learning_rate=0.19738321461148345, max_depth=9, min_split_loss=6.291786728306978, objective=binary:logistic, subsample=0.18204693546324435;, score=0.792 total time=   0.0s\n",
      "[CV 4/10] END eval_metric=error, learning_rate=0.19738321461148345, max_depth=9, min_split_loss=6.291786728306978, objective=binary:logistic, subsample=0.18204693546324435;, score=0.780 total time=   0.0s\n",
      "[CV 3/10] END eval_metric=error, learning_rate=0.19738321461148345, max_depth=9, min_split_loss=6.291786728306978, objective=binary:logistic, subsample=0.18204693546324435;, score=0.848 total time=   0.0s\n",
      "[CV 8/10] END eval_metric=error, learning_rate=0.3059083565755502, max_depth=7, min_split_loss=1.9772306696894415, objective=reg:logistic, subsample=0.1554404750389139;, score=0.791 total time=   0.1s\n",
      "[CV 6/10] END eval_metric=error, learning_rate=0.19738321461148345, max_depth=9, min_split_loss=6.291786728306978, objective=binary:logistic, subsample=0.18204693546324435;, score=0.808 total time=   0.0s\n",
      "[CV 9/10] END eval_metric=error, learning_rate=0.19738321461148345, max_depth=9, min_split_loss=6.291786728306978, objective=binary:logistic, subsample=0.18204693546324435;, score=0.763 total time=   0.0s\n",
      "[CV 8/10] END eval_metric=error, learning_rate=0.19738321461148345, max_depth=9, min_split_loss=6.291786728306978, objective=binary:logistic, subsample=0.18204693546324435;, score=0.763 total time=   0.0s\n",
      "[CV 7/10] END eval_metric=error, learning_rate=0.19738321461148345, max_depth=9, min_split_loss=6.291786728306978, objective=binary:logistic, subsample=0.18204693546324435;, score=0.811 total time=   0.0s\n",
      "[CV 10/10] END eval_metric=error, learning_rate=0.19738321461148345, max_depth=9, min_split_loss=6.291786728306978, objective=binary:logistic, subsample=0.18204693546324435;, score=0.835 total time=   0.0s\n",
      "[CV 10/10] END eval_metric=error, learning_rate=0.24517995936765524, max_depth=6, min_split_loss=2.5253349437857056, objective=binary:logistic, subsample=0.6575111505357728;, score=0.843 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=10,\n",
       "                   estimator=XGBRFClassifier(base_score=None, booster=None,\n",
       "                                             callbacks=None,\n",
       "                                             colsample_bylevel=None,\n",
       "                                             colsample_bytree=None, device=None,\n",
       "                                             early_stopping_rounds=None,\n",
       "                                             enable_categorical=False,\n",
       "                                             eval_metric=None,\n",
       "                                             feature_types=None, gamma=None,\n",
       "                                             grow_policy=None,\n",
       "                                             importance_type=None,\n",
       "                                             interaction_constraints=None,\n",
       "                                             max_bin=None,\n",
       "                                             max_cat_threshold=N...\n",
       "                                        &#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x159327dd0&gt;,\n",
       "                                        &#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x159326650&gt;,\n",
       "                                        &#x27;min_split_loss&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x159323fd0&gt;,\n",
       "                                        &#x27;objective&#x27;: [&#x27;reg:squarederror&#x27;,\n",
       "                                                      &#x27;binary:logistic&#x27;,\n",
       "                                                      &#x27;reg:logistic&#x27;],\n",
       "                                        &#x27;subsample&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x159007b90&gt;},\n",
       "                   verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=10,\n",
       "                   estimator=XGBRFClassifier(base_score=None, booster=None,\n",
       "                                             callbacks=None,\n",
       "                                             colsample_bylevel=None,\n",
       "                                             colsample_bytree=None, device=None,\n",
       "                                             early_stopping_rounds=None,\n",
       "                                             enable_categorical=False,\n",
       "                                             eval_metric=None,\n",
       "                                             feature_types=None, gamma=None,\n",
       "                                             grow_policy=None,\n",
       "                                             importance_type=None,\n",
       "                                             interaction_constraints=None,\n",
       "                                             max_bin=None,\n",
       "                                             max_cat_threshold=N...\n",
       "                                        &#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x159327dd0&gt;,\n",
       "                                        &#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x159326650&gt;,\n",
       "                                        &#x27;min_split_loss&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x159323fd0&gt;,\n",
       "                                        &#x27;objective&#x27;: [&#x27;reg:squarederror&#x27;,\n",
       "                                                      &#x27;binary:logistic&#x27;,\n",
       "                                                      &#x27;reg:logistic&#x27;],\n",
       "                                        &#x27;subsample&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x159007b90&gt;},\n",
       "                   verbose=3)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: XGBRFClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBRFClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bytree=None, device=None,\n",
       "                early_stopping_rounds=None, enable_categorical=False,\n",
       "                eval_metric=&#x27;error&#x27;, feature_types=None, gamma=None,\n",
       "                grow_policy=None, importance_type=None,\n",
       "                interaction_constraints=None,\n",
       "                learning_rate=np.float64(0.24517995936765524), max_bin=None,\n",
       "                max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "                min_child_weight=None,\n",
       "                min_split_loss=np.float64(2.5253349437857056), missing=nan,\n",
       "                monotone_constraints=None, multi_strategy=None,\n",
       "                n_estimators=None, n_jobs=None, num_parallel_tree=None,\n",
       "                objective=&#x27;binary:logistic&#x27;, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBRFClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBRFClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bytree=None, device=None,\n",
       "                early_stopping_rounds=None, enable_categorical=False,\n",
       "                eval_metric=&#x27;error&#x27;, feature_types=None, gamma=None,\n",
       "                grow_policy=None, importance_type=None,\n",
       "                interaction_constraints=None,\n",
       "                learning_rate=np.float64(0.24517995936765524), max_bin=None,\n",
       "                max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "                min_child_weight=None,\n",
       "                min_split_loss=np.float64(2.5253349437857056), missing=nan,\n",
       "                monotone_constraints=None, multi_strategy=None,\n",
       "                n_estimators=None, n_jobs=None, num_parallel_tree=None,\n",
       "                objective=&#x27;binary:logistic&#x27;, ...)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=10,\n",
       "                   estimator=XGBRFClassifier(base_score=None, booster=None,\n",
       "                                             callbacks=None,\n",
       "                                             colsample_bylevel=None,\n",
       "                                             colsample_bytree=None, device=None,\n",
       "                                             early_stopping_rounds=None,\n",
       "                                             enable_categorical=False,\n",
       "                                             eval_metric=None,\n",
       "                                             feature_types=None, gamma=None,\n",
       "                                             grow_policy=None,\n",
       "                                             importance_type=None,\n",
       "                                             interaction_constraints=None,\n",
       "                                             max_bin=None,\n",
       "                                             max_cat_threshold=N...\n",
       "                                        'learning_rate': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x159327dd0>,\n",
       "                                        'max_depth': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x159326650>,\n",
       "                                        'min_split_loss': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x159323fd0>,\n",
       "                                        'objective': ['reg:squarederror',\n",
       "                                                      'binary:logistic',\n",
       "                                                      'reg:logistic'],\n",
       "                                        'subsample': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x159007b90>},\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRFClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import randint\n",
    "\n",
    "model = XGBRFClassifier(random_state=42)\n",
    "params = {\n",
    "    \"learning_rate\": uniform(1e-2, 3e-1),\n",
    "    \"min_split_loss\": uniform(0, 10),\n",
    "    \"max_depth\": randint(3, 10),\n",
    "    \"subsample\": uniform(0, 1),\n",
    "    \"objective\": [\"reg:squarederror\", \"binary:logistic\", \"reg:logistic\"],\n",
    "    \"eval_metric\": [\"aucpr\", \"error\"]\n",
    "}\n",
    "\n",
    "model_grid = RandomizedSearchCV(model, param_distributions=params, n_jobs=-1, verbose=3, n_iter=10, cv=10)\n",
    "\n",
    "model_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best xgboost params\n",
      "{'eval_metric': 'error', 'learning_rate': np.float64(0.24517995936765524), 'max_depth': 6, 'min_split_loss': np.float64(2.5253349437857056), 'objective': 'binary:logistic', 'subsample': np.float64(0.6575111505357728)}\n",
      "Accuracy train 0.827323717948718\n",
      "Accuracy test 0.7913832199546486\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "best_model_xgboost_params = model_grid.best_params_\n",
    "print(\"Best xgboost params\")\n",
    "print(best_model_xgboost_params)\n",
    "\n",
    "y_pred_train = model_grid.predict(X_train)\n",
    "y_pred_test = model_grid.predict(X_test)\n",
    "print(\"Accuracy train\", accuracy_score(y_pred_train, y_train ))\n",
    "print(\"Accuracy test\", accuracy_score(y_pred_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost performance overview\n",
    "* Confusion matrix\n",
    "* Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test actual/predicted\n",
      "\n",
      "Predicted    0    1  All\n",
      "Actual                  \n",
      "0.0        207   28  235\n",
      "1.0         64  142  206\n",
      "All        271  170  441 \n",
      "\n",
      "Classification report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.88      0.82       235\n",
      "         1.0       0.84      0.69      0.76       206\n",
      "\n",
      "    accuracy                           0.79       441\n",
      "   macro avg       0.80      0.79      0.79       441\n",
      "weighted avg       0.80      0.79      0.79       441\n",
      " \n",
      "\n",
      "Train actual/predicted\n",
      "\n",
      "Predicted     0     1   All\n",
      "Actual                     \n",
      "0.0        1140   187  1327\n",
      "1.0         244   925  1169\n",
      "All        1384  1112  2496 \n",
      "\n",
      "Classification report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.86      0.84      1327\n",
      "         1.0       0.83      0.79      0.81      1169\n",
      "\n",
      "    accuracy                           0.83      2496\n",
      "   macro avg       0.83      0.83      0.83      2496\n",
      "weighted avg       0.83      0.83      0.83      2496\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "print(\"Test actual/predicted\\n\")\n",
    "print(pd.crosstab(y_test, y_pred_test, rownames=['Actual'], colnames=['Predicted'], margins=True),'\\n')\n",
    "print(\"Classification report\\n\")\n",
    "print(classification_report(y_test, y_pred_test),'\\n')\n",
    "\n",
    "conf_matrix = confusion_matrix(y_train, y_pred_train)\n",
    "print(\"Train actual/predicted\\n\")\n",
    "print(pd.crosstab(y_train, y_pred_train, rownames=['Actual'], colnames=['Predicted'], margins=True),'\\n')\n",
    "print(\"Classification report\\n\")\n",
    "print(classification_report(y_train, y_pred_train),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save best XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model = model_grid.best_estimator_\n",
    "xgboost_model_path = \"./artifacts/lead_model_xgboost.json\"\n",
    "xgboost_model.save_model(xgboost_model_path)\n",
    "\n",
    "model_results = {\n",
    "    xgboost_model_path: classification_report(y_train, y_pred_train, output_dict=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLearn logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV 1/3] END .......C=1.0, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .......C=1.0, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .......C=1.0, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END ........C=10, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ........C=10, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ........C=10, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=none, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=none, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=none, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=l1, solver=liblinear;, score=0.770 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=l1, solver=liblinear;, score=0.797 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=l1, solver=liblinear;, score=0.796 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END ....C=10, penalty=l2, solver=lbfgs;, score=0.817 total time=   0.0s\n",
      "[CV 2/3] END ....C=10, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.0s\n",
      "[CV 3/3] END ....C=10, penalty=l2, solver=lbfgs;, score=0.812 total time=   0.0s\n",
      "[CV 1/3] END .....C=10, penalty=l1, solver=saga;, score=0.820 total time=   0.0s\n",
      "[CV 2/3] END .....C=10, penalty=l1, solver=saga;, score=0.803 total time=   0.0s\n",
      "[CV 3/3] END .....C=10, penalty=l1, solver=saga;, score=0.814 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1.0, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1.0, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1.0, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "21 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py\", line 593, in safe_patch_function\n",
      "    patch_function(call_original, *args, **kwargs)\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py\", line 259, in patch_with_managed_run\n",
      "    result = patch_function(original, *args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/mlflow/sklearn/__init__.py\", line 1662, in patched_fit\n",
      "    return original(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py\", line 574, in call_original\n",
      "    return call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py\", line 509, in call_original_fn_with_event_logging\n",
      "    original_fn_result = original_fn(*og_args, **og_kwargs)\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py\", line 571, in _original_fn\n",
      "    original_result = original(*_og_args, **_og_kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py\", line 473, in safe_patch_function\n",
      "    return original(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py\", line 473, in safe_patch_function\n",
      "    return original(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py\", line 473, in safe_patch_function\n",
      "    return original(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py\", line 473, in safe_patch_function\n",
      "    return original(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py\", line 473, in safe_patch_function\n",
      "    return original(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/yasminebenmessaoud/anaconda3/envs/sdse_project/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan 0.78766026        nan\n",
      " 0.81129808 0.81209936        nan        nan]\n",
      "  warnings.warn(\n",
      "2025/12/01 09:00:22 INFO mlflow.sklearn.utils: Logging the 5 best runs, 5 runs will be omitted.\n",
      "2025/12/01 09:00:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lr params\n",
      "{'solver': 'saga', 'penalty': 'l1', 'C': 10}\n",
      "Accuracy train: 0.8145032051282052\n",
      "Accuracy test: 0.7845804988662132\n",
      "Test actual/predicted\n",
      "\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0.0        206   29  235\n",
      "1.0         66  140  206\n",
      "All        272  169  441 \n",
      "\n",
      "Classification report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.88      0.81       235\n",
      "         1.0       0.83      0.68      0.75       206\n",
      "\n",
      "    accuracy                           0.78       441\n",
      "   macro avg       0.79      0.78      0.78       441\n",
      "weighted avg       0.79      0.78      0.78       441\n",
      " \n",
      "\n",
      "Train actual/predicted\n",
      "\n",
      "Predicted   0.0   1.0   All\n",
      "Actual                     \n",
      "0.0        1134   193  1327\n",
      "1.0         270   899  1169\n",
      "All        1404  1092  2496 \n",
      "\n",
      "Classification report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.85      0.83      1327\n",
      "         1.0       0.82      0.77      0.80      1169\n",
      "\n",
      "    accuracy                           0.81      2496\n",
      "   macro avg       0.82      0.81      0.81      2496\n",
      "weighted avg       0.81      0.81      0.81      2496\n",
      " \n",
      "\n",
      "0.7818136117037215\n"
     ]
    }
   ],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "from sklearn.metrics import cohen_kappa_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "class lr_wrapper(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def predict(self, context, model_input):\n",
    "        return self.model.predict_proba(model_input)[:, 1]\n",
    "\n",
    "\n",
    "mlflow.sklearn.autolog(log_input_examples=True, log_models=False)\n",
    "experiment_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id) as run:\n",
    "    model = LogisticRegression()\n",
    "    lr_model_path = \"./artifacts/lead_model_lr.pkl\"\n",
    "\n",
    "    params = {\n",
    "              'solver': [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],\n",
    "              'penalty':  [\"none\", \"l1\", \"l2\", \"elasticnet\"],\n",
    "              'C' : [100, 10, 1.0, 0.1, 0.01]\n",
    "    }\n",
    "    model_grid = RandomizedSearchCV(model, param_distributions= params, verbose=3, n_iter=10, cv=3)\n",
    "    model_grid.fit(X_train, y_train)\n",
    "\n",
    "    best_model = model_grid.best_estimator_\n",
    "\n",
    "    y_pred_train = model_grid.predict(X_train)\n",
    "    y_pred_test = model_grid.predict(X_test)\n",
    "\n",
    "\n",
    "    # log artifacts\n",
    "    mlflow.log_metric('f1_score', f1_score(y_test, y_pred_test))\n",
    "    mlflow.log_artifacts(\"artifacts\", artifact_path=\"model\")\n",
    "    mlflow.log_param(\"data_version\", \"00000\")\n",
    "    \n",
    "    # store model for model interpretability\n",
    "    joblib.dump(value=model, filename=lr_model_path)\n",
    "        \n",
    "    # Custom python model for predicting probability \n",
    "    mlflow.pyfunc.log_model('model', python_model=lr_wrapper(model))\n",
    "\n",
    "\n",
    "model_classification_report = classification_report(y_test, y_pred_test, output_dict=True)\n",
    "\n",
    "best_model_lr_params = model_grid.best_params_\n",
    "\n",
    "print(\"Best lr params\")\n",
    "print(best_model_lr_params)\n",
    "\n",
    "print(\"Accuracy train:\", accuracy_score(y_pred_train, y_train ))\n",
    "print(\"Accuracy test:\", accuracy_score(y_pred_test, y_test))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "print(\"Test actual/predicted\\n\")\n",
    "print(pd.crosstab(y_test, y_pred_test, rownames=['Actual'], colnames=['Predicted'], margins=True),'\\n')\n",
    "print(\"Classification report\\n\")\n",
    "print(classification_report(y_test, y_pred_test),'\\n')\n",
    "\n",
    "conf_matrix = confusion_matrix(y_train, y_pred_train)\n",
    "print(\"Train actual/predicted\\n\")\n",
    "print(pd.crosstab(y_train, y_pred_train, rownames=['Actual'], colnames=['Predicted'], margins=True),'\\n')\n",
    "print(\"Classification report\\n\")\n",
    "print(classification_report(y_train, y_pred_train),'\\n')\n",
    "\n",
    "model_results[lr_model_path] = model_classification_report\n",
    "print(model_classification_report[\"weighted avg\"][\"f1-score\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save columns and model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'column_names': ['purchases', 'time_spent', 'n_visits', 'customer_group_2', 'customer_group_3', 'customer_group_4', 'customer_group_5', 'customer_group_6', 'customer_group_7', 'customer_group_8', 'customer_group_9', 'onboarding_True']}\n",
      "Saved column list to  ./artifacts/columns_list.json\n"
     ]
    }
   ],
   "source": [
    "column_list_path = './artifacts/columns_list.json'\n",
    "with open(column_list_path, 'w+') as columns_file:\n",
    "    columns = {'column_names': list(X_train.columns)}\n",
    "    print(columns)\n",
    "    json.dump(columns, columns_file)\n",
    "\n",
    "print('Saved column list to ', column_list_path)\n",
    "\n",
    "model_results_path = \"./artifacts/model_results.json\"\n",
    "with open(model_results_path, 'w+') as results_file:\n",
    "    json.dump(model_results, results_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL SELECTION\n",
    "\n",
    "Model selection involves choosing the most suitable statistical model from a set of candidates. In straightforward cases, this process uses an existing dataset. When candidate models offer comparable predictive or explanatory power, the simplest model is generally the preferred choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants used:\n",
    "current_date = datetime.datetime.now().strftime(\"%Y_%B_%d\")\n",
    "artifact_path = \"model\"\n",
    "model_name = \"lead_model\"\n",
    "experiment_name = current_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from mlflow.tracking.client import MlflowClient\n",
    "from mlflow.entities.model_registry.model_version_status import ModelVersionStatus\n",
    "from mlflow.tracking.client import MlflowClient\n",
    "\n",
    "def wait_until_ready(model_name, model_version):\n",
    "    client = MlflowClient()\n",
    "    for _ in range(10):\n",
    "        model_version_details = client.get_model_version(\n",
    "          name=model_name,\n",
    "          version=model_version,\n",
    "        )\n",
    "        status = ModelVersionStatus.from_string(model_version_details.status)\n",
    "        print(f\"Model status: {ModelVersionStatus.to_string(status)}\")\n",
    "        if status == ModelVersionStatus.READY:\n",
    "            break\n",
    "        time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting experiment model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['627272652637156136']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_ids = [mlflow.get_experiment_by_name(experiment_name).experiment_id]\n",
    "experiment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_id                                               87267f3f78084ede99e16e5ff5f2c703\n",
       "experiment_id                                                      627272652637156136\n",
       "status                                                                       FINISHED\n",
       "artifact_uri                        file:///Users/yasminebenmessaoud/Library/Cloud...\n",
       "start_time                                           2025-12-01 08:00:22.535000+00:00\n",
       "end_time                                             2025-12-01 08:00:25.127000+00:00\n",
       "metrics.training_log_loss                                                    0.418664\n",
       "metrics.training_score                                                       0.814503\n",
       "metrics.training_recall_score                                                0.814503\n",
       "metrics.best_cv_score                                                        0.812099\n",
       "metrics.f1_score                                                             0.746667\n",
       "metrics.f1_score_X_test                                                      0.746667\n",
       "metrics.training_accuracy_score                                              0.814503\n",
       "metrics.training_f1_score                                                     0.81396\n",
       "metrics.training_precision_score                                             0.814983\n",
       "metrics.training_roc_auc                                                     0.899123\n",
       "params.best_solver                                                               saga\n",
       "params.error_score                                                                nan\n",
       "params.pre_dispatch                                                          2*n_jobs\n",
       "params.refit                                                                     True\n",
       "params.best_C                                                                      10\n",
       "params.verbose                                                                      3\n",
       "params.data_version                                                             00000\n",
       "params.n_iter                                                                      10\n",
       "params.estimator                                                 LogisticRegression()\n",
       "params.best_penalty                                                                l1\n",
       "params.param_distributions          {'solver': ['newton-cg', 'lbfgs', 'liblinear',...\n",
       "params.return_train_score                                                       False\n",
       "params.scoring                                                                   None\n",
       "params.random_state                                                              None\n",
       "params.n_jobs                                                                    None\n",
       "params.cv                                                                           3\n",
       "tags.mlflow.log-model.history       [{\"run_id\": \"87267f3f78084ede99e16e5ff5f2c703\"...\n",
       "tags.estimator_class                sklearn.model_selection._search.RandomizedSear...\n",
       "tags.mlflow.source.type                                                         LOCAL\n",
       "tags.mlflow.runName                                                resilient-wasp-972\n",
       "tags.mlflow.user                                                   yasminebenmessaoud\n",
       "tags.mlflow.source.name             /Users/yasminebenmessaoud/anaconda3/envs/sdse_...\n",
       "tags.estimator_name                                                RandomizedSearchCV\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_best = mlflow.search_runs(\n",
    "    experiment_ids=experiment_ids,\n",
    "    order_by=[\"metrics.f1_score DESC\"],\n",
    "    max_results=1\n",
    ").iloc[0]\n",
    "experiment_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>./artifacts/lead_model_xgboost.json</th>\n",
       "      <td>0.827509</td>\n",
       "      <td>0.827324</td>\n",
       "      <td>0.826982</td>\n",
       "      <td>2496.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./artifacts/lead_model_lr.pkl</th>\n",
       "      <td>0.790542</td>\n",
       "      <td>0.784580</td>\n",
       "      <td>0.781814</td>\n",
       "      <td>441.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     precision    recall  f1-score  support\n",
       "./artifacts/lead_model_xgboost.json   0.827509  0.827324  0.826982   2496.0\n",
       "./artifacts/lead_model_lr.pkl         0.790542  0.784580  0.781814    441.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./artifacts/model_results.json\", \"r\") as f:\n",
    "    model_results = json.load(f)\n",
    "results_df = pd.DataFrame({model: val[\"weighted avg\"] for model, val in model_results.items()}).T\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: ./artifacts/lead_model_xgboost.json\n"
     ]
    }
   ],
   "source": [
    "best_model = results_df.sort_values(\"f1-score\", ascending=False).iloc[0].name\n",
    "print(f\"Best model: {best_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get production model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model in production\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "prod_model = [model for model in client.search_model_versions(f\"name='{model_name}'\") if dict(model)['current_stage']=='Production']\n",
    "prod_model_exists = len(prod_model)>0\n",
    "\n",
    "if prod_model_exists:\n",
    "    prod_model_version = dict(prod_model[0])['version']\n",
    "    prod_model_run_id = dict(prod_model[0])['run_id']\n",
    "    \n",
    "    print('Production model name: ', model_name)\n",
    "    print('Production model version:', prod_model_version)\n",
    "    print('Production model run id:', prod_model_run_id)\n",
    "    \n",
    "else:\n",
    "    print('No model in production')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare prod and best trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model in production\n",
      "Registered model: 87267f3f78084ede99e16e5ff5f2c703\n"
     ]
    }
   ],
   "source": [
    "train_model_score = experiment_best[\"metrics.f1_score\"]\n",
    "model_details = {}\n",
    "model_status = {}\n",
    "run_id = None\n",
    "\n",
    "if prod_model_exists:\n",
    "    data, details = mlflow.get_run(prod_model_run_id)\n",
    "    prod_model_score = data[1][\"metrics.f1_score\"]\n",
    "\n",
    "    model_status[\"current\"] = train_model_score\n",
    "    model_status[\"prod\"] = prod_model_score\n",
    "\n",
    "    if train_model_score>prod_model_score:\n",
    "        print(\"Registering new model\")\n",
    "        run_id = experiment_best[\"run_id\"]\n",
    "else:\n",
    "    print(\"No model in production\")\n",
    "    run_id = experiment_best[\"run_id\"]\n",
    "\n",
    "print(f\"Registered model: {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_id is not None:\n",
    "    print(f'Best model found: {run_id}')\n",
    "\n",
    "    model_uri = \"runs:/{run_id}/{artifact_path}\".format(\n",
    "        run_id=run_id,\n",
    "        artifact_path=artifact_path\n",
    "    )\n",
    "    model_details = mlflow.register_model(model_uri=model_uri, name=model_name)\n",
    "    wait_until_ready(model_details.name, model_details.version)\n",
    "    model_details = dict(model_details)\n",
    "    print(model_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEPLOY\n",
    "\n",
    "A model version can be assigned to one or more stages. MLflow provides predefined stages for common use cases: None, Staging, Production, and Archived. With the necessary permissions, you can transition a model version between stages or request a transition to a different stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transition to staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "\n",
    "def wait_for_deployment(model_name, model_version, stage='Staging'):\n",
    "    status = False\n",
    "    while not status:\n",
    "        model_version_details = dict(\n",
    "            client.get_model_version(name=model_name,version=model_version)\n",
    "            )\n",
    "        if model_version_details['current_stage'] == stage:\n",
    "            print(f'Transition completed to {stage}')\n",
    "            status = True\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(2)\n",
    "    return status\n",
    "\n",
    "model_version_details = dict(client.get_model_version(name=model_name,version=model_version))\n",
    "model_status = True\n",
    "if model_version_details['current_stage'] != 'Staging':\n",
    "    client.transition_model_version_stage(\n",
    "        name=model_name,\n",
    "        version=model_version,stage=\"Staging\", \n",
    "        archive_existing_versions=True\n",
    "    )\n",
    "    model_status = wait_for_deployment(model_name, model_version, 'Staging')\n",
    "else:\n",
    "    print('Model already in staging')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdse_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
